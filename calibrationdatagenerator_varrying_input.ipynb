{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKZ124PJzMas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599df23a-7116-4db0-b31a-e0cefc4a20c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dishwasher': 0, 'toilet_tm': 0, 'sink_tm': 0, 'toilet_km': 0, 'shower_tm': 0, 'shower_km': 0, 'hose': 0, 'laundry': 0}\n"
          ]
        }
      ],
      "source": [
        "# Define a dictionary to hold appliance names as keys and corresponding data groups as values\n",
        "appliance_tuple = (\n",
        "    ([\"dishwasher\"], [\n",
        "        ('05/04/2024 23:19:28', '01410593'),\n",
        "        ('05/04/2024 23:19:38', '01410594'),\n",
        "        ('05/04/2024 23:19:49', '01410599'),\n",
        "        ('05/04/2024 23:19:59', '01410604'),\n",
        "        ('05/04/2024 23:20:10', '01410606'),\n",
        "        ('05/04/2024 23:20:20', '01410610'),\n",
        "        ('05/04/2024 23:20:31', '01410611'),\n",
        "        ('05/04/2024 23:20:52', '01410612'),\n",
        "        ('05/04/2024 23:21:54', '01410612'),\n",
        "        ('05/04/2024 23:22:26', '01410613'),\n",
        "        ('05/04/2024 23:23:08', '01410614'),\n",
        "        ('05/04/2024 23:23:18', '01410616'),\n",
        "        ('05/04/2024 23:23:28', '01410618'),\n",
        "        ('05/04/2024 23:23:39', '01410620'),\n",
        "        ('05/04/2024 23:23:50', '01410622'),\n",
        "        ('05/04/2024 23:24:00', '01410624'),\n",
        "        ('05/04/2024 23:24:11', '01410625'),\n",
        "        ('05/04/2024 23:24:42', '01410628'),\n",
        "        ('05/04/2024 23:24:52', '01410632'),\n",
        "        ('05/04/2024 23:25:03', '01410634'),\n",
        "        ('05/04/2024 23:29:25', '01410636'),\n",
        "        ('05/04/2024 23:29:35', '01410638'),\n",
        "        ('05/04/2024 23:29:45', '01410640'),\n",
        "        ('05/04/2024 23:29:56', '01410642'),\n",
        "        ('05/04/2024 23:30:06', '01410644'),\n",
        "        ('05/05/2024 00:26:59', '01410645'),\n",
        "        ('05/05/2024 00:27:52', '01410646'),\n",
        "        ('05/05/2024 00:28:44', '01410647'),\n",
        "        ('05/05/2024 00:28:55', '01410651'),\n",
        "        ('05/05/2024 00:29:05', '01410659'),\n",
        "        ('05/05/2024 00:29:15', '01410661'),\n",
        "        ('05/05/2024 00:29:47', '01410662'),\n",
        "        ('05/05/2024 00:30:39', '01410663'),\n",
        "        ('05/05/2024 00:31:31', '01410664'),\n",
        "        ('05/05/2024 00:32:24', '01410665'),\n",
        "        ('05/05/2024 00:33:16', '01410666'),\n",
        "        ('05/05/2024 00:34:09', '01410667'),\n",
        "        ('05/05/2024 00:34:40', '01410669'),\n",
        "        ('05/05/2024 00:34:51', '01410671'),\n",
        "        ('05/05/2024 00:35:01', '01410673'),\n",
        "        ('05/05/2024 00:35:12', '01410675'),\n",
        "        ('05/05/2024 00:35:22', '01410678'),\n",
        "        ('05/05/2024 00:35:33', '01410679'),\n",
        "        ('05/05/2024 00:36:36', '01410680'),\n",
        "        ('05/05/2024 00:37:28', '01410681'),\n",
        "        ('05/05/2024 00:38:20', '01410682'),\n",
        "        ('05/05/2024 00:39:13', '01410683'),\n",
        "        ('05/05/2024 00:40:16', '01410684'),\n",
        "        ('05/05/2024 00:41:08', '01410685'),\n",
        "        ('05/05/2024 00:42:00', '01410686'),\n",
        "        ('05/05/2024 00:42:53', '01410687'),\n",
        "        ('05/05/2024 00:43:34', '01410688'),\n",
        "        ('05/05/2024 00:43:45', '01410690'),\n",
        "        ('05/05/2024 00:43:56', '01410693'),\n",
        "        ('05/05/2024 00:44:06', '01410695'),\n",
        "        ('05/05/2024 00:44:17', '01410697'),\n",
        "        ('05/05/2024 00:44:27', '01410698'),\n",
        "        ('05/05/2024 00:44:38', '01410699'),\n",
        "        ('05/05/2024 00:45:41', '01410700'),\n",
        "        ('05/05/2024 01:54:05', '01410707'),\n",
        "        ('05/05/2024 01:54:15', '01410712')\n",
        "    ]),\n",
        "\n",
        "    ([\"toilet_tm\"], [\n",
        "        ('05/05/2024 11:52:26', '01410818'),\n",
        "        ('05/05/2024 11:52:36', '01410819'),\n",
        "        ('05/05/2024 11:52:47', '01410826'),\n",
        "        ('05/05/2024 11:52:57', '01410833'),\n",
        "    ]),\n",
        "\n",
        "    ([\"sink_tm\"], [\n",
        "        ('05/05/2024 11:56:48', '01410833'),\n",
        "        ('05/05/2024 11:56:58', '01410834'),\n",
        "    ]),\n",
        "\n",
        "    ([\"toilet_km\"], [\n",
        "        ('05/05/2024 12:05:00', '01410834'),\n",
        "        ('05/05/2024 12:05:10', '01410835'),\n",
        "        ('05/05/2024 12:05:21', '01410839'),\n",
        "        ('05/05/2024 12:05:31', '01410845'),\n",
        "        ('05/05/2024 12:05:42', '01410848')\n",
        "    ]),\n",
        "\n",
        "    ([\"shower_tm\"], [\n",
        "        ('05/05/2024 12:24:12', '01411062'),\n",
        "        ('05/05/2024 12:24:22', '01411063'),\n",
        "        ('05/05/2024 12:24:33', '01411064'),\n",
        "        ('05/05/2024 12:24:43', '01411065'),\n",
        "        ('05/05/2024 12:24:54', '01411066'),\n",
        "        ('05/05/2024 12:25:04', '01411067'),\n",
        "        ('05/05/2024 12:25:15', '01411068')\n",
        "    ]),\n",
        "\n",
        "    ([\"shower_km\"], [\n",
        "        ('05/05/2024 12:50:23', '01411084'),\n",
        "        ('05/05/2024 12:50:33', '01411086'),\n",
        "        ('05/05/2024 12:50:44', '01411088'),\n",
        "        ('05/05/2024 12:50:54', '01411090'),\n",
        "        ('05/05/2024 12:51:05', '01411093'),\n",
        "        ('05/05/2024 12:51:15', '01411095'),\n",
        "        ('05/05/2024 12:51:25', '01411097'),\n",
        "        ('05/05/2024 12:51:36', '01411099'),\n",
        "        ('05/05/2024 12:51:47', '01411101'),\n",
        "        ('05/05/2024 12:51:57', '01411103'),\n",
        "        ('05/05/2024 12:52:08', '01411105'),\n",
        "        ('05/05/2024 12:52:18', '01411107'),\n",
        "        ('05/05/2024 12:52:29', '01411109'),\n",
        "        ('05/05/2024 12:52:39', '01411111'),\n",
        "        ('05/05/2024 12:52:49', '01411113'),\n",
        "        ('05/05/2024 12:53:00', '01411115'),\n",
        "        ('05/05/2024 12:53:10', '01411117'),\n",
        "        ('05/05/2024 12:53:21', '01411119'),\n",
        "        ('05/05/2024 12:53:31', '01411121'),\n",
        "        ('05/05/2024 12:53:42', '01411122'),\n",
        "        ('05/05/2024 12:53:52', '01411124'),\n",
        "        ('05/05/2024 12:54:03', '01411126'),\n",
        "        ('05/05/2024 12:54:13', '01411128'),\n",
        "        ('05/05/2024 12:54:24', '01411130'),\n",
        "        ('05/05/2024 12:54:34', '01411132'),\n",
        "        ('05/05/2024 12:54:45', '01411134'),\n",
        "        ('05/05/2024 12:54:55', '01411136'),\n",
        "        ('05/05/2024 12:55:06', '01411137'),\n",
        "        ('05/05/2024 12:55:16', '01411139'),\n",
        "        ('05/05/2024 12:55:27', '01411141'),\n",
        "        ('05/05/2024 12:55:37', '01411143'),\n",
        "        ('05/05/2024 12:55:47', '01411145'),\n",
        "        ('05/05/2024 12:55:58', '01411147'),\n",
        "        ('05/05/2024 12:56:08', '01411148'),\n",
        "        ('05/05/2024 12:56:19', '01411150'),\n",
        "        ('05/05/2024 12:56:29', '01411152'),\n",
        "        ('05/05/2024 12:56:40', '01411154'),\n",
        "        ('05/05/2024 12:56:50', '01411156'),\n",
        "        ('05/05/2024 12:57:01', '01411157'),\n",
        "        ('05/05/2024 12:57:11', '01411159'),\n",
        "        ('05/05/2024 12:57:22', '01411161'),\n",
        "        ('05/05/2024 12:57:32', '01411163'),\n",
        "        ('05/05/2024 12:57:43', '01411165'),\n",
        "        ('05/05/2024 12:57:53', '01411166'),\n",
        "        ('05/05/2024 12:58:04', '01411168'),\n",
        "        ('05/05/2024 12:58:14', '01411170'),\n",
        "        ('05/05/2024 12:58:25', '01411172'),\n",
        "        ('05/05/2024 12:58:35', '01411174'),\n",
        "        ('05/05/2024 12:58:46', '01411175'),\n",
        "        ('05/05/2024 12:58:56', '01411177'),\n",
        "        ('05/05/2024 12:59:06', '01411179'),\n",
        "        ('05/05/2024 12:59:17', '01411181'),\n",
        "        ('05/05/2024 12:59:27', '01411182'),\n",
        "        ('05/05/2024 12:59:38', '01411184'),\n",
        "        ('05/05/2024 12:59:49', '01411186'),\n",
        "        ('05/05/2024 12:59:59', '01411188'),\n",
        "        ('05/05/2024 13:00:10', '01411190'),\n",
        "        ('05/05/2024 13:00:20', '01411191'),\n",
        "        ('05/05/2024 13:00:31', '01411193'),\n",
        "        ('05/05/2024 13:00:41', '01411195'),\n",
        "        ('05/05/2024 13:00:52', '01411197'),\n",
        "        ('05/05/2024 13:01:02', '01411198'),\n",
        "        ('05/05/2024 13:01:12', '01411200'),\n",
        "        ('05/05/2024 13:01:23', '01411202'),\n",
        "        ('05/05/2024 13:01:33', '01411204'),\n",
        "        ('05/05/2024 13:01:44', '01411205'),\n",
        "        ('05/05/2024 13:01:55', '01411207'),\n",
        "        ('05/05/2024 13:02:05', '01411208')\n",
        "    ]),\n",
        "\n",
        "    ([\"hose\"], [\n",
        "        ('05/05/2024 12:13:44', '01410862'),\n",
        "        ('05/05/2024 12:13:54', '01410870'),\n",
        "        ('05/05/2024 12:14:05', '01410878'),\n",
        "        ('05/05/2024 12:14:15', '01410887'),\n",
        "        ('05/05/2024 12:14:25', '01410895'),\n",
        "        ('05/05/2024 12:14:36', '01410903'),\n",
        "        ('05/05/2024 12:14:46', '01410911'),\n",
        "        ('05/05/2024 12:14:57', '01410920'),\n",
        "        ('05/05/2024 12:15:07', '01410928'),\n",
        "        ('05/05/2024 12:15:18', '01410936'),\n",
        "        ('05/05/2024 12:15:28', '01410945'),\n",
        "        ('05/05/2024 12:15:39', '01410953'),\n",
        "        ('05/05/2024 12:15:49', '01410961'),\n",
        "        ('05/05/2024 12:16:00', '01410970'),\n",
        "        ('05/05/2024 12:16:10', '01410978'),\n",
        "        ('05/05/2024 12:16:21', '01410986'),\n",
        "        ('05/05/2024 12:16:31', '01410994'),\n",
        "        ('05/05/2024 12:16:42', '01411003'),\n",
        "        ('05/05/2024 12:16:52', '01411011'),\n",
        "        ('05/05/2024 12:17:03', '01411014'),\n",
        "        ('05/05/2024 12:17:13', '01411021'),\n",
        "        ('05/05/2024 12:17:23', '01411029'),\n",
        "        ('05/05/2024 12:17:34', '01411037'),\n",
        "        ('05/05/2024 12:17:45', '01411046'),\n",
        "        ('05/05/2024 12:17:55', '01411054'),\n",
        "        ('05/05/2024 12:18:06', '01411060')\n",
        "    ]),\n",
        "\n",
        "    ([\"laundry\"], [\n",
        "        ('05/05/2024 22:47:22', '01412061'),\n",
        "        ('05/05/2024 22:47:33', '01412066'),\n",
        "        ('05/05/2024 22:51:13', '01412067'),\n",
        "        ('05/05/2024 22:51:23', '01412068'),\n",
        "        ('05/05/2024 22:51:34', '01412069'),\n",
        "        ('05/05/2024 22:51:44', '01412070'),\n",
        "        ('05/05/2024 22:51:55', '01412071'),\n",
        "        ('05/05/2024 22:52:05', '01412072'),\n",
        "        ('05/05/2024 22:52:16', '01412073'),\n",
        "        ('05/05/2024 22:52:37', '01412074'),\n",
        "        ('05/05/2024 22:52:47', '01412075'),\n",
        "        ('05/05/2024 22:52:58', '01412076'),\n",
        "        ('05/05/2024 22:53:08', '01412077'),\n",
        "        ('05/05/2024 22:53:29', '01412081'),\n",
        "        ('05/05/2024 22:53:40', '01412086'),\n",
        "        ('05/05/2024 22:53:50', '01412087'),\n",
        "        ('05/05/2024 22:58:54', '01412091'),\n",
        "        ('05/05/2024 22:59:04', '01412094'),\n",
        "        ('05/05/2024 22:59:15', '01412099'),\n",
        "        ('05/05/2024 22:59:25', '01412103'),\n",
        "        ('05/05/2024 22:59:36', '01412108'),\n",
        "        ('05/05/2024 22:59:46', '01412112'),\n",
        "        ('05/05/2024 22:59:56', '01412116'),\n",
        "        ('05/05/2024 23:00:07', '01412121'),\n",
        "        ('05/05/2024 23:00:17', '01412125'),\n",
        "        ('05/05/2024 23:00:28', '01412130'),\n",
        "        ('05/05/2024 23:00:38', '01412135'),\n",
        "        ('05/05/2024 23:00:49', '01412136'),\n",
        "        ('05/05/2024 23:00:59', '01412138'),\n",
        "        ('05/05/2024 23:01:10', '01412142'),\n",
        "        ('05/05/2024 23:01:20', '01412143'),\n",
        "        ('05/05/2024 23:01:31', '01412147'),\n",
        "        ('05/05/2024 23:01:41', '01412148'),\n",
        "        ('05/05/2024 23:04:18', '01412149'),\n",
        "        ('05/05/2024 23:04:29', '01412152'),\n",
        "        ('05/05/2024 23:04:39', '01412154'),\n",
        "        ('05/05/2024 23:05:00', '01412156'),\n",
        "        ('05/05/2024 23:05:21', '01412158'),\n",
        "        ('05/05/2024 23:05:31', '01412159'),\n",
        "        ('05/05/2024 23:05:42', '01412161'),\n",
        "        ('05/05/2024 23:09:22', '01412163'),\n",
        "        ('05/05/2024 23:09:32', '01412164'),\n",
        "        ('05/05/2024 23:09:43', '01412166'),\n",
        "        ('05/05/2024 23:09:53', '01412167'),\n",
        "        ('05/05/2024 23:10:04', '01412169'),\n",
        "        ('05/05/2024 23:10:14', '01412170'),\n",
        "        ('05/05/2024 23:10:56', '01412172'),\n",
        "        ('05/05/2024 23:15:39', '01412176'),\n",
        "        ('05/05/2024 23:15:49', '01412181'),\n",
        "        ('05/05/2024 23:16:00', '01412185'),\n",
        "        ('05/05/2024 23:16:10', '01412188'),\n",
        "        ('05/05/2024 23:16:20', '01412192'),\n",
        "        ('05/05/2024 23:16:31', '01412197'),\n",
        "        ('05/05/2024 23:16:41', '01412201'),\n",
        "        ('05/05/2024 23:16:52', '01412206'),\n",
        "        ('05/05/2024 23:17:02', '01412210'),\n",
        "        ('05/05/2024 23:17:13', '01412212'),\n",
        "        ('05/05/2024 23:19:08', '01412215'),\n",
        "        ('05/05/2024 23:19:18', '01412216'),\n",
        "        ('05/05/2024 23:20:21', '01412218'),\n",
        "        ('05/05/2024 23:20:32', '01412222'),\n",
        "        ('05/05/2024 23:20:42', '01412227'),\n",
        "        ('05/05/2024 23:20:52', '01412231'),\n",
        "        ('05/05/2024 23:21:03', '01412235'),\n",
        "        ('05/05/2024 23:21:13', '01412236'),\n",
        "        ('05/05/2024 23:21:24', '01412239'),\n",
        "        ('05/05/2024 23:21:34', '01412243'),\n",
        "        ('05/05/2024 23:21:45', '01412247'),\n",
        "        ('05/05/2024 23:21:55', '01412252'),\n",
        "        ('05/05/2024 23:24:01', '01412254'),\n",
        "        ('05/05/2024 23:24:12', '01412257'),\n",
        "        ('05/05/2024 23:24:22', '01412261'),\n",
        "        ('05/05/2024 23:24:32', '01412265'),\n",
        "        ('05/05/2024 23:24:43', '01412267'),\n",
        "        ('05/06/2024 00:25:59', '01412267'),\n",
        "        ('05/06/2024 01:26:11', '01412272'),\n",
        "        ('05/06/2024 01:26:21', '01412274')\n",
        "    ]),\n",
        ")\n",
        "\n",
        "\n",
        "appliance_info_dict = {'dishwasher': [0,False],\n",
        "                       \"toilet_tm\": [0, False],\n",
        "                       \"sink_tm\": [0, True],\n",
        "                       \"toilet_km\": [0, False],\n",
        "                       \"shower_tm\": [0, True],\n",
        "                       \"shower_km\": [0, True],\n",
        "                       \"hose\": [0, True],\n",
        "                       \"laundry\": [0, False]}\n",
        "\n",
        "appliance_gallon_dict = {key: value[0] for key, value in appliance_info_dict.items()}\n",
        "print(appliance_gallon_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def change_in_points(appliance_tuple):\n",
        "        \"\"\"\n",
        "        Calculate changes in water meter readings and timestamps for each appliance in the tuple.\n",
        "\n",
        "        :param appliance_tuple: tuple, containing multiple appliances and their usage data\n",
        "        :return: tuple, containing multiple appliances and their modified usage data\n",
        "        \"\"\"\n",
        "        modified_tuple = []\n",
        "\n",
        "        # Iterate over each appliance and its data\n",
        "        for appliance, data in appliance_tuple:\n",
        "            output = {'dishwasher': 0, 'toilet_tm': 0, 'sink_tm': 0, 'toilet_km': 0, 'shower_tm': 0, 'shower_km': 0, 'hose': 0, 'laundry': 0}\n",
        "\n",
        "            # Extract timestamps and water meter readings\n",
        "            timestamps = [entry[0] for entry in data]\n",
        "            readings = [int(entry[1]) / 10.0 for entry in data]\n",
        "\n",
        "            # Calculate change in water meter reading\n",
        "            changes_readings = [readings[i + 1] - readings[i] for i in range(len(readings) - 1)]\n",
        "\n",
        "            # Calculate change in timestamps\n",
        "            changes_timestamps = [\n",
        "                (datetime.strptime(timestamps[i + 1], '%m/%d/%Y %H:%M:%S') - datetime.strptime(timestamps[i],\n",
        "                                                                                               '%m/%d/%Y %H:%M:%S')).total_seconds()\n",
        "                for i in range(len(timestamps) - 1)\n",
        "            ]\n",
        "\n",
        "            # Round down changes in timestamps to the nearest 10 seconds\n",
        "            rounded_changes_timestamps = [round(change / 10.0) * 10 for change in changes_timestamps]\n",
        "\n",
        "            # Combine timestamps and changes\n",
        "            combined_data = list(zip(rounded_changes_timestamps, changes_readings))\n",
        "\n",
        "            output[appliance[0]] = sum(pair[1] for pair in combined_data)\n",
        "\n",
        "            # Append the appliance and its modified data to the result list\n",
        "            modified_tuple.append((appliance, combined_data, list(output.values())))\n",
        "\n",
        "        return modified_tuple\n",
        "\n",
        "print(change_in_points(appliance_tuple))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz1IqGV4fznw",
        "outputId": "8f3876ad-006b-423c-fe55-6538ff977242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['dishwasher'], [(10, 0.10000000000582077), (10, 0.5), (10, 0.5), (10, 0.20000000001164153), (10, 0.39999999999417923), (10, 0.10000000000582077), (20, 0.10000000000582077), (60, 0.0), (30, 0.09999999997671694), (40, 0.10000000000582077), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.10000000000582077), (30, 0.29999999998835847), (10, 0.40000000002328306), (10, 0.1999999999825377), (260, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (3410, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (10, 0.39999999999417923), (10, 0.7999999999883585), (10, 0.20000000001164153), (30, 0.10000000000582077), (50, 0.09999999997671694), (50, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (30, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.29999999998835847), (10, 0.10000000000582077), (60, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.09999999997671694), (60, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (50, 0.10000000000582077), (40, 0.09999999997671694), (10, 0.20000000001164153), (10, 0.29999999998835847), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.09999999997671694), (10, 0.10000000000582077), (60, 0.10000000000582077), (4100, 0.7000000000116415), (10, 0.5)], [11.900000000023283, 0, 0, 0, 0, 0, 0, 0]), (['toilet_tm'], [(10, 0.10000000000582077), (10, 0.7000000000116415), (10, 0.6999999999825377)], [0, 1.5, 0, 0, 0, 0, 0, 0]), (['sink_tm'], [(10, 0.10000000000582077)], [0, 0, 0.10000000000582077, 0, 0, 0, 0, 0]), (['toilet_km'], [(10, 0.10000000000582077), (10, 0.39999999999417923), (10, 0.6000000000058208), (10, 0.29999999998835847)], [0, 0, 0, 1.3999999999941792, 0, 0, 0, 0]), (['shower_tm'], [(10, 0.09999999997671694), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.09999999997671694)], [0, 0, 0, 0, 0.5999999999767169, 0, 0, 0]), (['shower_km'], [(10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.29999999998835847), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.09999999997671694), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.10000000000582077), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.09999999997671694), (10, 0.20000000001164153), (10, 0.20000000001164153), (10, 0.1999999999825377), (10, 0.10000000000582077), (10, 0.20000000001164153), (10, 0.09999999997671694)], [0, 0, 0, 0, 0, 12.39999999999418, 0, 0]), (['hose'], [(10, 0.7999999999883585), (10, 0.7999999999883585), (10, 0.9000000000232831), (10, 0.7999999999883585), (10, 0.7999999999883585), (10, 0.8000000000174623), (10, 0.8999999999941792), (10, 0.7999999999883585), (10, 0.8000000000174623), (10, 0.8999999999941792), (10, 0.7999999999883585), (10, 0.8000000000174623), (10, 0.8999999999941792), (10, 0.7999999999883585), (10, 0.8000000000174623), (10, 0.7999999999883585), (10, 0.8999999999941792), (10, 0.8000000000174623), (10, 0.29999999998835847), (10, 0.7000000000116415), (10, 0.7999999999883585), (10, 0.8000000000174623), (10, 0.8999999999941792), (10, 0.7999999999883585), (10, 0.6000000000058208)], [0, 0, 0, 0, 0, 0, 19.79999999998836, 0]), (['laundry'], [(10, 0.5), (220, 0.10000000000582077), (10, 0.09999999997671694), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.09999999997671694), (20, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (10, 0.10000000000582077), (20, 0.39999999999417923), (10, 0.5), (10, 0.10000000000582077), (300, 0.39999999999417923), (10, 0.29999999998835847), (10, 0.5), (10, 0.39999999999417923), (10, 0.5), (10, 0.40000000002328306), (10, 0.39999999999417923), (10, 0.5), (10, 0.39999999999417923), (10, 0.5), (10, 0.5), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.40000000002328306), (10, 0.09999999997671694), (10, 0.40000000002328306), (10, 0.09999999997671694), (160, 0.10000000000582077), (10, 0.3000000000174623), (10, 0.1999999999825377), (20, 0.20000000001164153), (20, 0.1999999999825377), (10, 0.10000000000582077), (10, 0.20000000001164153), (220, 0.1999999999825377), (10, 0.10000000000582077), (10, 0.20000000001164153), (10, 0.10000000000582077), (10, 0.1999999999825377), (10, 0.10000000000582077), (40, 0.20000000001164153), (280, 0.39999999999417923), (10, 0.5), (10, 0.39999999999417923), (10, 0.29999999998835847), (10, 0.40000000002328306), (10, 0.5), (10, 0.39999999999417923), (10, 0.5), (10, 0.39999999999417923), (10, 0.20000000001164153), (120, 0.29999999998835847), (10, 0.10000000000582077), (60, 0.1999999999825377), (10, 0.40000000002328306), (10, 0.5), (10, 0.39999999999417923), (10, 0.39999999999417923), (10, 0.10000000000582077), (10, 0.29999999998835847), (10, 0.39999999999417923), (10, 0.40000000002328306), (10, 0.5), (130, 0.1999999999825377), (10, 0.3000000000174623), (10, 0.39999999999417923), (10, 0.39999999999417923), (10, 0.20000000001164153), (3680, 0.0), (3610, 0.5), (10, 0.1999999999825377)], [0, 0, 0, 0, 0, 0, 0, 21.29999999998836])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2b8KoGYgHmL",
        "outputId": "58d82b66-c12e-43e2-a45e-da4e6a5babb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HERE\n",
            "Epoch 1/1000\n",
            "5/5 [==============================] - 12s 1s/step - loss: 5406.7866 - val_loss: 5406.7749\n",
            "Epoch 2/1000\n",
            "5/5 [==============================] - 2s 542ms/step - loss: 5406.7749 - val_loss: 5406.7749\n",
            "Epoch 3/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5406.7749 - val_loss: 5406.7749\n",
            "Epoch 4/1000\n",
            "5/5 [==============================] - 3s 665ms/step - loss: 5406.7749 - val_loss: 5406.7749\n",
            "Epoch 5/1000\n",
            "5/5 [==============================] - 3s 317ms/step - loss: 5406.7734 - val_loss: 5406.4722\n",
            "Epoch 6/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5401.1211 - val_loss: 5394.6143\n",
            "Epoch 7/1000\n",
            "5/5 [==============================] - 4s 626ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 8/1000\n",
            "5/5 [==============================] - 5s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 9/1000\n",
            "5/5 [==============================] - 4s 901ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 10/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 376ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 11/1000\n",
            "1/5 [=====>........................] - ETA: 0s - loss: 0.4075"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 4s 943ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 12/1000\n",
            "5/5 [==============================] - 4s 884ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 13/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 14/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 15/1000\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 16/1000\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 17/1000\n",
            "5/5 [==============================] - 3s 791ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 18/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 19/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 20/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7640.7759HERE\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 21/1000\n",
            "5/5 [==============================] - 2s 377ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 22/1000\n",
            "5/5 [==============================] - 4s 782ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 23/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 24/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 25/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 26/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 27/1000\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 28/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 29/1000\n",
            "5/5 [==============================] - 2s 569ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 30/1000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 7640.7759HERE\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 31/1000\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 32/1000\n",
            "5/5 [==============================] - 3s 860ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 33/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 34/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 35/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 36/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 37/1000\n",
            "5/5 [==============================] - 3s 828ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 38/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 39/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 40/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 41/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 42/1000\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 43/1000\n",
            "5/5 [==============================] - 3s 806ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 44/1000\n",
            "5/5 [==============================] - 2s 583ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 45/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 46/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 47/1000\n",
            "5/5 [==============================] - 2s 534ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 48/1000\n",
            "5/5 [==============================] - 3s 591ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 49/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 50/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 539ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 51/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 52/1000\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 53/1000\n",
            "5/5 [==============================] - 3s 567ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 54/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 55/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 56/1000\n",
            "5/5 [==============================] - 2s 531ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 57/1000\n",
            "5/5 [==============================] - 3s 427ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 58/1000\n",
            "5/5 [==============================] - 3s 725ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 59/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 60/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 382ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 61/1000\n",
            "5/5 [==============================] - 2s 601ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 62/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 63/1000\n",
            "5/5 [==============================] - 3s 800ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 64/1000\n",
            "5/5 [==============================] - 3s 622ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 65/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 66/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 67/1000\n",
            "5/5 [==============================] - 3s 630ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 68/1000\n",
            "5/5 [==============================] - 2s 583ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 69/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 70/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 540ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 71/1000\n",
            "5/5 [==============================] - 2s 593ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 72/1000\n",
            "5/5 [==============================] - 3s 791ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 73/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 74/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 75/1000\n",
            "5/5 [==============================] - 2s 377ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 76/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 77/1000\n",
            "5/5 [==============================] - 3s 709ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 78/1000\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 79/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 80/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 81/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 82/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 83/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 84/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 85/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 86/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 87/1000\n",
            "5/5 [==============================] - 3s 739ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 88/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 89/1000\n",
            "5/5 [==============================] - 2s 534ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 90/1000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 7632.1382HERE\n",
            "5/5 [==============================] - 2s 266ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 91/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 92/1000\n",
            "5/5 [==============================] - 3s 610ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 93/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 94/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 95/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 96/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 97/1000\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 98/1000\n",
            "5/5 [==============================] - 2s 546ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 99/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 100/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552 HERE\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 101/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 102/1000\n",
            "5/5 [==============================] - 2s 423ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 103/1000\n",
            "5/5 [==============================] - 3s 361ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 104/1000\n",
            "5/5 [==============================] - 2s 532ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 105/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 106/1000\n",
            "5/5 [==============================] - 2s 502ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 107/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 108/1000\n",
            "5/5 [==============================] - 3s 846ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 109/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 110/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 111/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 112/1000\n",
            "5/5 [==============================] - 3s 834ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 113/1000\n",
            "5/5 [==============================] - 3s 441ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 114/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 115/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 116/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 117/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 118/1000\n",
            "5/5 [==============================] - 2s 465ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 119/1000\n",
            "5/5 [==============================] - 3s 807ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 120/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 378ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 121/1000\n",
            "5/5 [==============================] - 3s 786ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 122/1000\n",
            "5/5 [==============================] - 3s 658ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 123/1000\n",
            "5/5 [==============================] - 3s 687ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 124/1000\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 125/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 126/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 127/1000\n",
            "5/5 [==============================] - 2s 574ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 128/1000\n",
            "5/5 [==============================] - 3s 729ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 129/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 130/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7632.1382HERE\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 131/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 132/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 133/1000\n",
            "5/5 [==============================] - 3s 723ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 134/1000\n",
            "5/5 [==============================] - 3s 633ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 135/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 136/1000\n",
            "5/5 [==============================] - 2s 251ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 137/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 138/1000\n",
            "5/5 [==============================] - 2s 498ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 139/1000\n",
            "5/5 [==============================] - 3s 806ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 140/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 563ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 141/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 142/1000\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 143/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 144/1000\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 145/1000\n",
            "5/5 [==============================] - 3s 788ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 146/1000\n",
            "5/5 [==============================] - 2s 279ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 147/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 148/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 149/1000\n",
            "5/5 [==============================] - 2s 500ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 150/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 578ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 151/1000\n",
            "5/5 [==============================] - 2s 252ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 152/1000\n",
            "5/5 [==============================] - 2s 253ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 153/1000\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 154/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 155/1000\n",
            "5/5 [==============================] - 3s 823ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 156/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 157/1000\n",
            "5/5 [==============================] - 2s 360ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 158/1000\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 159/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 160/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 3s 791ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 161/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 162/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 163/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 164/1000\n",
            "5/5 [==============================] - 2s 573ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 165/1000\n",
            "5/5 [==============================] - 3s 351ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 166/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 167/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 168/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 169/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 170/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 5s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 171/1000\n",
            "5/5 [==============================] - 5s 1s/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 172/1000\n",
            "5/5 [==============================] - 3s 633ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 173/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 174/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 175/1000\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 176/1000\n",
            "5/5 [==============================] - 3s 836ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 177/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 178/1000\n",
            "5/5 [==============================] - 3s 588ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 179/1000\n",
            "5/5 [==============================] - 2s 253ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 180/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 3s 776ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 181/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 182/1000\n",
            "5/5 [==============================] - 2s 253ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 183/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 184/1000\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 185/1000\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 186/1000\n",
            "5/5 [==============================] - 3s 809ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 187/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 188/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 189/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 190/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 191/1000\n",
            "5/5 [==============================] - 3s 687ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 192/1000\n",
            "5/5 [==============================] - 2s 545ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 193/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 194/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 195/1000\n",
            "5/5 [==============================] - 2s 584ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 196/1000\n",
            "5/5 [==============================] - 3s 545ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 197/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 198/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 199/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 200/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 201/1000\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 202/1000\n",
            "5/5 [==============================] - 3s 262ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 203/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 204/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 205/1000\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 206/1000\n",
            "5/5 [==============================] - 2s 587ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 207/1000\n",
            "5/5 [==============================] - 3s 804ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 208/1000\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 209/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 210/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7045.0815 HERE\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 211/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 212/1000\n",
            "5/5 [==============================] - 3s 602ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 213/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 214/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 215/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 216/1000\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 217/1000\n",
            "5/5 [==============================] - 3s 424ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 218/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 219/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 220/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7640.7759 HERE\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 221/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 222/1000\n",
            "5/5 [==============================] - 4s 597ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 223/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 224/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 225/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 226/1000\n",
            "5/5 [==============================] - 3s 656ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 227/1000\n",
            "5/5 [==============================] - 3s 699ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 228/1000\n",
            "5/5 [==============================] - 2s 613ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 229/1000\n",
            "5/5 [==============================] - 2s 360ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 230/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552HERE\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 231/1000\n",
            "5/5 [==============================] - 3s 814ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 232/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 233/1000\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 234/1000\n",
            "5/5 [==============================] - 3s 842ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 235/1000\n",
            "5/5 [==============================] - 4s 784ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 236/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 237/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 238/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 239/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 240/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 3s 502ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 241/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 242/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 243/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 244/1000\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 245/1000\n",
            "5/5 [==============================] - 3s 834ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 246/1000\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 247/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 248/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 249/1000\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 250/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 588ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 251/1000\n",
            "5/5 [==============================] - 3s 776ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 252/1000\n",
            "5/5 [==============================] - 2s 359ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 253/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 254/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 255/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 256/1000\n",
            "5/5 [==============================] - 3s 753ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 257/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 258/1000\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 259/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 260/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 261/1000\n",
            "5/5 [==============================] - 3s 536ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 262/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 263/1000\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 264/1000\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 265/1000\n",
            "5/5 [==============================] - 3s 413ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 266/1000\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 267/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 268/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 269/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 270/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 425ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 271/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 272/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 273/1000\n",
            "5/5 [==============================] - 2s 538ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 274/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 275/1000\n",
            "5/5 [==============================] - 3s 729ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 276/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 277/1000\n",
            "5/5 [==============================] - 2s 602ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 278/1000\n",
            "5/5 [==============================] - 3s 782ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 279/1000\n",
            "5/5 [==============================] - 3s 746ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 280/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 588ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 281/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 282/1000\n",
            "5/5 [==============================] - 2s 253ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 283/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 284/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 285/1000\n",
            "5/5 [==============================] - 3s 831ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 286/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 287/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 288/1000\n",
            "5/5 [==============================] - 3s 752ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 289/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 290/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 829ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 291/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 292/1000\n",
            "5/5 [==============================] - 2s 360ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 293/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 294/1000\n",
            "5/5 [==============================] - 2s 575ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 295/1000\n",
            "5/5 [==============================] - 3s 786ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 296/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 297/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 298/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 299/1000\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 300/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 660ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 301/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 302/1000\n",
            "5/5 [==============================] - 2s 502ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 303/1000\n",
            "5/5 [==============================] - 2s 253ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 304/1000\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 305/1000\n",
            "5/5 [==============================] - 3s 735ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 306/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 307/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 308/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 309/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 310/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 3s 727ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 311/1000\n",
            "5/5 [==============================] - 3s 637ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 312/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 313/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 314/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 315/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 316/1000\n",
            "5/5 [==============================] - 4s 945ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 317/1000\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 318/1000\n",
            "5/5 [==============================] - 2s 358ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 319/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 320/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 321/1000\n",
            "5/5 [==============================] - 3s 531ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 322/1000\n",
            "5/5 [==============================] - 3s 430ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 323/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 324/1000\n",
            "5/5 [==============================] - 2s 265ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 325/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 326/1000\n",
            "5/5 [==============================] - 4s 607ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 327/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 328/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 329/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 330/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 586ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 331/1000\n",
            "5/5 [==============================] - 3s 737ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 332/1000\n",
            "5/5 [==============================] - 3s 626ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 333/1000\n",
            "5/5 [==============================] - 4s 636ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 334/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 335/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 336/1000\n",
            "5/5 [==============================] - 3s 708ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 337/1000\n",
            "5/5 [==============================] - 3s 636ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 338/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 339/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 340/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552 HERE\n",
            "5/5 [==============================] - 2s 389ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 341/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 342/1000\n",
            "5/5 [==============================] - 3s 606ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 343/1000\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 344/1000\n",
            "5/5 [==============================] - 3s 607ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 345/1000\n",
            "5/5 [==============================] - 2s 597ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 346/1000\n",
            "5/5 [==============================] - 2s 605ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 347/1000\n",
            "5/5 [==============================] - 3s 775ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 348/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 349/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 350/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 351/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 352/1000\n",
            "5/5 [==============================] - 3s 769ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 353/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 354/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 355/1000\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 356/1000\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 357/1000\n",
            "5/5 [==============================] - 3s 754ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 358/1000\n",
            "5/5 [==============================] - 3s 682ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 359/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 360/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524 HERE\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 361/1000\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 362/1000\n",
            "5/5 [==============================] - 2s 457ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 363/1000\n",
            "5/5 [==============================] - 3s 342ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 364/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 365/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 366/1000\n",
            "5/5 [==============================] - 2s 501ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 367/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 368/1000\n",
            "5/5 [==============================] - 3s 388ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 369/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 370/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 371/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 372/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 373/1000\n",
            "5/5 [==============================] - 3s 724ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 374/1000\n",
            "5/5 [==============================] - 3s 634ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 375/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 376/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 377/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 378/1000\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 379/1000\n",
            "5/5 [==============================] - 3s 604ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 380/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 593ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 381/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 382/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 383/1000\n",
            "5/5 [==============================] - 2s 607ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 384/1000\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 385/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 386/1000\n",
            "5/5 [==============================] - 2s 252ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 387/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 388/1000\n",
            "5/5 [==============================] - 2s 575ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 389/1000\n",
            "5/5 [==============================] - 4s 916ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 390/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 3s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 391/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 392/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 393/1000\n",
            "5/5 [==============================] - 2s 577ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 394/1000\n",
            "5/5 [==============================] - 3s 362ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 395/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 396/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 397/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 398/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 399/1000\n",
            "5/5 [==============================] - 3s 713ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 400/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7640.7759HERE\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 401/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 402/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 403/1000\n",
            "5/5 [==============================] - 2s 534ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 404/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 405/1000\n",
            "5/5 [==============================] - 3s 432ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 406/1000\n",
            "5/5 [==============================] - 3s 785ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 407/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 408/1000\n",
            "5/5 [==============================] - 3s 774ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 409/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 410/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 534ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 411/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 412/1000\n",
            "5/5 [==============================] - 2s 371ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 413/1000\n",
            "5/5 [==============================] - 3s 691ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 414/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 415/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 416/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 417/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 418/1000\n",
            "5/5 [==============================] - 3s 849ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 419/1000\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 420/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 421/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 422/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 423/1000\n",
            "5/5 [==============================] - 2s 612ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 424/1000\n",
            "5/5 [==============================] - 3s 325ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 425/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 426/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 427/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 428/1000\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 429/1000\n",
            "5/5 [==============================] - 3s 442ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 430/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7045.0815HERE\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 431/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 432/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 433/1000\n",
            "5/5 [==============================] - 3s 504ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 434/1000\n",
            "5/5 [==============================] - 3s 652ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 435/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 436/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 437/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 438/1000\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 439/1000\n",
            "5/5 [==============================] - 3s 610ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 440/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 3s 761ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 441/1000\n",
            "5/5 [==============================] - 3s 613ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 442/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 443/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 444/1000\n",
            "5/5 [==============================] - 3s 858ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 445/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 446/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 447/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 448/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 449/1000\n",
            "5/5 [==============================] - 4s 801ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 450/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 451/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 452/1000\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 453/1000\n",
            "5/5 [==============================] - 3s 822ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 454/1000\n",
            "5/5 [==============================] - 3s 799ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 455/1000\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 456/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 457/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 458/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 459/1000\n",
            "5/5 [==============================] - 4s 937ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 460/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 461/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 462/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 463/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 464/1000\n",
            "5/5 [==============================] - 3s 846ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 465/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 466/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 467/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 468/1000\n",
            "5/5 [==============================] - 3s 800ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 469/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 470/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7640.7759 HERE\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 471/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 472/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 473/1000\n",
            "5/5 [==============================] - 2s 574ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 474/1000\n",
            "5/5 [==============================] - 3s 305ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 475/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 476/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 477/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 478/1000\n",
            "5/5 [==============================] - 3s 734ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 479/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 480/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 481/1000\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 482/1000\n",
            "5/5 [==============================] - 3s 786ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 483/1000\n",
            "5/5 [==============================] - 3s 626ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 484/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 485/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 486/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 487/1000\n",
            "5/5 [==============================] - 3s 763ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 488/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 489/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 490/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 491/1000\n",
            "5/5 [==============================] - 2s 590ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 492/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 493/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 494/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 495/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 496/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 497/1000\n",
            "5/5 [==============================] - 3s 596ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 498/1000\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 499/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 500/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7529HERE\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 501/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 502/1000\n",
            "5/5 [==============================] - 3s 611ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 503/1000\n",
            "5/5 [==============================] - 3s 354ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 504/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 505/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 506/1000\n",
            "5/5 [==============================] - 4s 614ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 507/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 508/1000\n",
            "5/5 [==============================] - 2s 361ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 509/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 510/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7529HERE\n",
            "5/5 [==============================] - 2s 590ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 511/1000\n",
            "5/5 [==============================] - 3s 358ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 512/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 513/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 514/1000\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 515/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 516/1000\n",
            "5/5 [==============================] - 3s 427ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 517/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 518/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 519/1000\n",
            "5/5 [==============================] - 2s 264ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 520/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 266ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 521/1000\n",
            "5/5 [==============================] - 4s 945ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 522/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 523/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 524/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 525/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 526/1000\n",
            "5/5 [==============================] - 4s 774ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 527/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 528/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 529/1000\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 530/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7529HERE\n",
            "5/5 [==============================] - 3s 818ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 531/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 532/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 533/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 534/1000\n",
            "5/5 [==============================] - 3s 442ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 535/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 536/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 537/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 538/1000\n",
            "5/5 [==============================] - 3s 623ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 539/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 540/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 503ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 541/1000\n",
            "5/5 [==============================] - 2s 265ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 542/1000\n",
            "5/5 [==============================] - 4s 915ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 543/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 544/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 545/1000\n",
            "5/5 [==============================] - 2s 266ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 546/1000\n",
            "5/5 [==============================] - 2s 266ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 547/1000\n",
            "5/5 [==============================] - 4s 997ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 548/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 549/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 550/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 551/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 552/1000\n",
            "5/5 [==============================] - 4s 795ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 553/1000\n",
            "5/5 [==============================] - 3s 777ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 554/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 555/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 556/1000\n",
            "5/5 [==============================] - 2s 376ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 557/1000\n",
            "5/5 [==============================] - 2s 306ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 558/1000\n",
            "5/5 [==============================] - 3s 767ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 559/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 560/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 561/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 562/1000\n",
            "5/5 [==============================] - 2s 384ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 563/1000\n",
            "5/5 [==============================] - 3s 353ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 564/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 565/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 566/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 567/1000\n",
            "5/5 [==============================] - 3s 440ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 568/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 569/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 570/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7640.7759HERE\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 571/1000\n",
            "5/5 [==============================] - 3s 753ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 572/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 573/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 574/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 575/1000\n",
            "5/5 [==============================] - 3s 694ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 576/1000\n",
            "5/5 [==============================] - 3s 437ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 577/1000\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 578/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 579/1000\n",
            "5/5 [==============================] - 3s 398ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 580/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552HERE\n",
            "5/5 [==============================] - 3s 745ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 581/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 582/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 583/1000\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 584/1000\n",
            "5/5 [==============================] - 4s 785ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 585/1000\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 586/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 587/1000\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 588/1000\n",
            "5/5 [==============================] - 3s 867ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 589/1000\n",
            "5/5 [==============================] - 4s 879ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 590/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 2s 586ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 591/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 592/1000\n",
            "5/5 [==============================] - 2s 590ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 593/1000\n",
            "5/5 [==============================] - 3s 525ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 594/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 595/1000\n",
            "5/5 [==============================] - 2s 590ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 596/1000\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 597/1000\n",
            "5/5 [==============================] - 3s 863ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 598/1000\n",
            "5/5 [==============================] - 3s 621ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 599/1000\n",
            "5/5 [==============================] - 3s 772ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 600/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7045.0815 HERE\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 601/1000\n",
            "5/5 [==============================] - 3s 847ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 602/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 603/1000\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 604/1000\n",
            "5/5 [==============================] - 2s 371ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 605/1000\n",
            "5/5 [==============================] - 3s 547ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 606/1000\n",
            "5/5 [==============================] - 3s 373ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 607/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 608/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 609/1000\n",
            "5/5 [==============================] - 3s 655ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 610/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 3s 302ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 611/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 612/1000\n",
            "5/5 [==============================] - 2s 591ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 613/1000\n",
            "5/5 [==============================] - 2s 591ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 614/1000\n",
            "5/5 [==============================] - 3s 811ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 615/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 616/1000\n",
            "5/5 [==============================] - 2s 535ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 617/1000\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 618/1000\n",
            "5/5 [==============================] - 3s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 619/1000\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 620/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7529HERE\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 621/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 622/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 623/1000\n",
            "5/5 [==============================] - 3s 356ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 624/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 625/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 626/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 627/1000\n",
            "5/5 [==============================] - 4s 866ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 628/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 629/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 630/1000\n",
            "3/5 [=================>............] - ETA: 1s - loss: 7632.1382HERE\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 631/1000\n",
            "5/5 [==============================] - 3s 639ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 632/1000\n",
            "5/5 [==============================] - 3s 710ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 633/1000\n",
            "5/5 [==============================] - 3s 438ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 634/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 635/1000\n",
            "5/5 [==============================] - 3s 721ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 636/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 637/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 638/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 639/1000\n",
            "5/5 [==============================] - 3s 450ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 640/1000\n",
            "3/5 [=================>............] - ETA: 0s - loss: 7632.1382HERE\n",
            "5/5 [==============================] - 2s 264ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 641/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 642/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 643/1000\n",
            "5/5 [==============================] - 4s 824ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 644/1000\n",
            "5/5 [==============================] - 2s 599ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 645/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 646/1000\n",
            "5/5 [==============================] - 2s 499ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 647/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 648/1000\n",
            "5/5 [==============================] - 4s 885ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 649/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 650/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 651/1000\n",
            "5/5 [==============================] - 2s 330ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 652/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 653/1000\n",
            "5/5 [==============================] - 4s 990ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 654/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 655/1000\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 656/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 657/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 658/1000\n",
            "5/5 [==============================] - 3s 815ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 659/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 660/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 661/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 662/1000\n",
            "5/5 [==============================] - 3s 780ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 663/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 664/1000\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 665/1000\n",
            "5/5 [==============================] - 2s 386ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 666/1000\n",
            "5/5 [==============================] - 2s 589ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 667/1000\n",
            "5/5 [==============================] - 3s 764ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 668/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 669/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 670/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 671/1000\n",
            "5/5 [==============================] - 3s 764ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 672/1000\n",
            "5/5 [==============================] - 2s 576ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 673/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 674/1000\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 675/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 676/1000\n",
            "5/5 [==============================] - 3s 366ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 677/1000\n",
            "5/5 [==============================] - 3s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 678/1000\n",
            "5/5 [==============================] - 2s 504ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 679/1000\n",
            "5/5 [==============================] - 2s 603ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 680/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552 HERE\n",
            "5/5 [==============================] - 2s 377ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 681/1000\n",
            "5/5 [==============================] - 3s 857ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 682/1000\n",
            "5/5 [==============================] - 2s 507ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 683/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 684/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 685/1000\n",
            "5/5 [==============================] - 2s 531ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 686/1000\n",
            "5/5 [==============================] - 4s 961ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 687/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 688/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 689/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 690/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 3s 626ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 691/1000\n",
            "5/5 [==============================] - 3s 441ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 692/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 693/1000\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 694/1000\n",
            "5/5 [==============================] - 3s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 695/1000\n",
            "5/5 [==============================] - 3s 775ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 696/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 697/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 698/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 699/1000\n",
            "5/5 [==============================] - 2s 588ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 700/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 701/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 702/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 703/1000\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 704/1000\n",
            "5/5 [==============================] - 3s 450ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 705/1000\n",
            "5/5 [==============================] - 2s 547ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 706/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 707/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 708/1000\n",
            "5/5 [==============================] - 2s 333ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 709/1000\n",
            "5/5 [==============================] - 4s 867ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 710/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 541ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 711/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 712/1000\n",
            "5/5 [==============================] - 2s 254ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 713/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 714/1000\n",
            "5/5 [==============================] - 3s 792ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 715/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 716/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 717/1000\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 718/1000\n",
            "5/5 [==============================] - 2s 602ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 719/1000\n",
            "5/5 [==============================] - 3s 332ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 720/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 721/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 722/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 723/1000\n",
            "5/5 [==============================] - 2s 530ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 724/1000\n",
            "5/5 [==============================] - 3s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 725/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 726/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 727/1000\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 728/1000\n",
            "5/5 [==============================] - 3s 763ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 729/1000\n",
            "5/5 [==============================] - 3s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 730/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 820ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 731/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 732/1000\n",
            "5/5 [==============================] - 3s 403ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 733/1000\n",
            "5/5 [==============================] - 3s 667ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 734/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 735/1000\n",
            "5/5 [==============================] - 2s 363ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 736/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 737/1000\n",
            "5/5 [==============================] - 2s 594ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 738/1000\n",
            "5/5 [==============================] - 3s 749ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 739/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 740/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 495ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 741/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 742/1000\n",
            "5/5 [==============================] - 2s 587ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 743/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 744/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 745/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 746/1000\n",
            "5/5 [==============================] - 3s 439ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 747/1000\n",
            "5/5 [==============================] - 3s 648ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 748/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 749/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 750/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 751/1000\n",
            "5/5 [==============================] - 2s 300ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 752/1000\n",
            "5/5 [==============================] - 3s 771ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 753/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 754/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 755/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 756/1000\n",
            "5/5 [==============================] - 3s 762ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 757/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 758/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 759/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 760/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 617ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 761/1000\n",
            "5/5 [==============================] - 3s 743ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 762/1000\n",
            "5/5 [==============================] - 2s 362ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 763/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 764/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 765/1000\n",
            "5/5 [==============================] - 3s 357ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 766/1000\n",
            "5/5 [==============================] - 2s 258ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 767/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 768/1000\n",
            "5/5 [==============================] - 2s 528ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 769/1000\n",
            "5/5 [==============================] - 4s 974ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 770/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 271ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 771/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 772/1000\n",
            "5/5 [==============================] - 2s 255ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 773/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 774/1000\n",
            "5/5 [==============================] - 3s 795ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 775/1000\n",
            "5/5 [==============================] - 2s 383ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 776/1000\n",
            "5/5 [==============================] - 2s 525ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 777/1000\n",
            "5/5 [==============================] - 2s 510ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 778/1000\n",
            "5/5 [==============================] - 4s 878ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 779/1000\n",
            "5/5 [==============================] - 3s 835ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 780/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 781/1000\n",
            "5/5 [==============================] - 2s 357ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 782/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 783/1000\n",
            "5/5 [==============================] - 2s 598ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 784/1000\n",
            "5/5 [==============================] - 3s 718ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 785/1000\n",
            "5/5 [==============================] - 3s 399ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 786/1000\n",
            "5/5 [==============================] - 2s 505ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 787/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 788/1000\n",
            "5/5 [==============================] - 2s 538ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 789/1000\n",
            "5/5 [==============================] - 4s 1s/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 790/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524 HERE\n",
            "5/5 [==============================] - 3s 271ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 791/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 792/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 793/1000\n",
            "5/5 [==============================] - 2s 326ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 794/1000\n",
            "5/5 [==============================] - 3s 529ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 795/1000\n",
            "5/5 [==============================] - 2s 256ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 796/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 797/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 798/1000\n",
            "5/5 [==============================] - 3s 838ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 799/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 800/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 801/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 802/1000\n",
            "5/5 [==============================] - 2s 529ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 803/1000\n",
            "5/5 [==============================] - 3s 767ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 804/1000\n",
            "5/5 [==============================] - 2s 284ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 805/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 806/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 807/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 808/1000\n",
            "5/5 [==============================] - 3s 728ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 809/1000\n",
            "5/5 [==============================] - 3s 663ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 810/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 811/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 812/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 813/1000\n",
            "5/5 [==============================] - 3s 384ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 814/1000\n",
            "5/5 [==============================] - 3s 746ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 815/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 816/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 817/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 818/1000\n",
            "5/5 [==============================] - 3s 839ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 819/1000\n",
            "5/5 [==============================] - 2s 506ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 820/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 821/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 822/1000\n",
            "5/5 [==============================] - 2s 584ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 823/1000\n",
            "5/5 [==============================] - 3s 753ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 824/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 825/1000\n",
            "5/5 [==============================] - 2s 518ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 826/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 827/1000\n",
            "5/5 [==============================] - 3s 684ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 828/1000\n",
            "5/5 [==============================] - 3s 658ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 829/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 830/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 831/1000\n",
            "5/5 [==============================] - 2s 600ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 832/1000\n",
            "5/5 [==============================] - 3s 795ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 833/1000\n",
            "5/5 [==============================] - 2s 265ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 834/1000\n",
            "5/5 [==============================] - 2s 283ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 835/1000\n",
            "5/5 [==============================] - 2s 549ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 836/1000\n",
            "5/5 [==============================] - 2s 445ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 837/1000\n",
            "5/5 [==============================] - 4s 967ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 838/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 839/1000\n",
            "5/5 [==============================] - 2s 269ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 840/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 588ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 841/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 842/1000\n",
            "5/5 [==============================] - 3s 483ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 843/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 844/1000\n",
            "5/5 [==============================] - 2s 366ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 845/1000\n",
            "5/5 [==============================] - 2s 586ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 846/1000\n",
            "5/5 [==============================] - 3s 580ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 847/1000\n",
            "5/5 [==============================] - 2s 533ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 848/1000\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 849/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 850/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524 HERE\n",
            "5/5 [==============================] - 3s 703ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 851/1000\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 852/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 853/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 854/1000\n",
            "5/5 [==============================] - 2s 523ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 855/1000\n",
            "5/5 [==============================] - 3s 661ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 856/1000\n",
            "5/5 [==============================] - 2s 367ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 857/1000\n",
            "5/5 [==============================] - 2s 580ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 858/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 859/1000\n",
            "5/5 [==============================] - 2s 449ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 860/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 3s 749ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 861/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 862/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 863/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 864/1000\n",
            "5/5 [==============================] - 2s 578ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 865/1000\n",
            "5/5 [==============================] - 3s 772ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 866/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 867/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 868/1000\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 869/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 870/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 3s 421ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 871/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 872/1000\n",
            "5/5 [==============================] - 2s 585ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 873/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 874/1000\n",
            "5/5 [==============================] - 2s 268ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 875/1000\n",
            "5/5 [==============================] - 4s 600ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 876/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 877/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 878/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 879/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 880/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 4s 934ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 881/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 882/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 883/1000\n",
            "5/5 [==============================] - 2s 381ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 884/1000\n",
            "5/5 [==============================] - 3s 862ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 885/1000\n",
            "5/5 [==============================] - 3s 850ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 886/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 887/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 888/1000\n",
            "5/5 [==============================] - 3s 438ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 889/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 890/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 5731.7524HERE\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 891/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 892/1000\n",
            "5/5 [==============================] - 3s 432ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 893/1000\n",
            "5/5 [==============================] - 3s 467ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 894/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 895/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 896/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 897/1000\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 898/1000\n",
            "5/5 [==============================] - 3s 421ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 899/1000\n",
            "5/5 [==============================] - 2s 369ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 900/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 901/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 902/1000\n",
            "5/5 [==============================] - 3s 717ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 903/1000\n",
            "5/5 [==============================] - 3s 674ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 904/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 905/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 906/1000\n",
            "5/5 [==============================] - 2s 257ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 907/1000\n",
            "5/5 [==============================] - 2s 604ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 908/1000\n",
            "5/5 [==============================] - 3s 760ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 909/1000\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 910/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7045.0815 HERE\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 911/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 912/1000\n",
            "5/5 [==============================] - 3s 445ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 913/1000\n",
            "5/5 [==============================] - 2s 365ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 914/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 915/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 916/1000\n",
            "5/5 [==============================] - 2s 375ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 917/1000\n",
            "5/5 [==============================] - 3s 437ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 918/1000\n",
            "5/5 [==============================] - 2s 577ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 919/1000\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 920/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552 HERE\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 921/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 922/1000\n",
            "5/5 [==============================] - 3s 728ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 923/1000\n",
            "5/5 [==============================] - 2s 267ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 924/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 925/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 926/1000\n",
            "5/5 [==============================] - 3s 626ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 927/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 928/1000\n",
            "5/5 [==============================] - 2s 380ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 929/1000\n",
            "5/5 [==============================] - 2s 267ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 930/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 3s 665ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 931/1000\n",
            "5/5 [==============================] - 2s 340ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 932/1000\n",
            "5/5 [==============================] - 3s 373ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 933/1000\n",
            "5/5 [==============================] - 2s 278ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 934/1000\n",
            "5/5 [==============================] - 3s 614ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 935/1000\n",
            "5/5 [==============================] - 2s 260ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 936/1000\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 937/1000\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 938/1000\n",
            "5/5 [==============================] - 2s 269ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 939/1000\n",
            "5/5 [==============================] - 3s 664ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 940/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6147HERE\n",
            "5/5 [==============================] - 3s 272ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 941/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 942/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 943/1000\n",
            "5/5 [==============================] - 2s 533ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 944/1000\n",
            "5/5 [==============================] - 2s 275ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 945/1000\n",
            "5/5 [==============================] - 3s 810ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 946/1000\n",
            "5/5 [==============================] - 2s 556ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 947/1000\n",
            "5/5 [==============================] - 2s 262ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 948/1000\n",
            "5/5 [==============================] - 2s 259ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 949/1000\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 950/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 449ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 951/1000\n",
            "5/5 [==============================] - 2s 374ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 952/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 953/1000\n",
            "5/5 [==============================] - 2s 521ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 954/1000\n",
            "5/5 [==============================] - 3s 688ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 955/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 956/1000\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 957/1000\n",
            "5/5 [==============================] - 2s 368ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 958/1000\n",
            "5/5 [==============================] - 3s 732ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 959/1000\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 960/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143 HERE\n",
            "5/5 [==============================] - 2s 264ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 961/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 962/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 963/1000\n",
            "5/5 [==============================] - 3s 522ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 964/1000\n",
            "5/5 [==============================] - 2s 527ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 965/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 966/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 967/1000\n",
            "5/5 [==============================] - 3s 620ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 968/1000\n",
            "5/5 [==============================] - 2s 584ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 969/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 970/1000\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 7053.0552HERE\n",
            "5/5 [==============================] - 2s 263ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 971/1000\n",
            "5/5 [==============================] - 2s 602ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 972/1000\n",
            "5/5 [==============================] - 3s 762ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 973/1000\n",
            "5/5 [==============================] - 2s 526ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 974/1000\n",
            "5/5 [==============================] - 2s 359ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 975/1000\n",
            "5/5 [==============================] - 2s 261ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 976/1000\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 977/1000\n",
            "5/5 [==============================] - 3s 811ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 978/1000\n",
            "5/5 [==============================] - 2s 370ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 979/1000\n",
            "5/5 [==============================] - 2s 364ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 980/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 773ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 981/1000\n",
            "5/5 [==============================] - 3s 568ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 982/1000\n",
            "5/5 [==============================] - 2s 531ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 983/1000\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 984/1000\n",
            "5/5 [==============================] - 2s 606ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 985/1000\n",
            "5/5 [==============================] - 2s 531ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 986/1000\n",
            "5/5 [==============================] - 3s 344ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 987/1000\n",
            "5/5 [==============================] - 2s 508ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 988/1000\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 989/1000\n",
            "5/5 [==============================] - 2s 372ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 990/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 991/1000\n",
            "5/5 [==============================] - 4s 875ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 992/1000\n",
            "5/5 [==============================] - 2s 533ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 993/1000\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 994/1000\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 995/1000\n",
            "5/5 [==============================] - 3s 748ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 996/1000\n",
            "5/5 [==============================] - 3s 646ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 997/1000\n",
            "5/5 [==============================] - 2s 264ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 998/1000\n",
            "5/5 [==============================] - 2s 373ms/step - loss: 5394.6143 - val_loss: 5394.6143\n",
            "Epoch 999/1000\n",
            "5/5 [==============================] - 2s 454ms/step - loss: 5394.6147 - val_loss: 5394.6143\n",
            "Epoch 1000/1000\n",
            "5/5 [==============================] - ETA: 0s - loss: 5394.6143HERE\n",
            "5/5 [==============================] - 3s 791ms/step - loss: 5394.6143 - val_loss: 5394.6143\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import psutil\n",
        "\n",
        "\n",
        "class CalibrationDataGenerator():\n",
        "\n",
        "    def __init__(self, appliance_info_dict, appliance_tuple1):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        appliance_info_dict (dict): {appliance_string_name: [gallons (int)), continuous flow/fixed flow (boolean)]}\n",
        "        appliance_tuple (tuple): (appliance_string_name: [tuples (seconds, water meter reading)]}\n",
        "\n",
        "        \"\"\"\n",
        "        self.appliance_gallon_dict = {key: value[0] for key, value in appliance_info_dict.items()}\n",
        "        self.appliance_boolean_continous_dict = {key: value[1] for key, value in appliance_info_dict.items()}\n",
        "\n",
        "        self.updated_calibrated_data = self.change_in_points(appliance_tuple1)\n",
        "\n",
        "    def remove_tuples_based_on_random_selection(self, random_tuple, tuple2):\n",
        "        first_values = set(random_tuple[0])\n",
        "\n",
        "        # Filter out tuples in tuple2 that have any of the first values in their first element\n",
        "        tuple2 = tuple(filter(lambda x: not any(item in first_values for item in x[0]), tuple2))\n",
        "\n",
        "        return tuple2\n",
        "\n",
        "    def get_data(self):\n",
        "        final_copy = self.updated_calibrated_data.copy()\n",
        "        x = []\n",
        "        y = []\n",
        "\n",
        "        # create extended appliances to x and y\n",
        "        copy = self.updated_calibrated_data.copy()\n",
        "        for _ in range(2):\n",
        "            for (a, b, c) in copy:\n",
        "                if self.appliance_boolean_continous_dict[a[0]] == True:\n",
        "                    appliance, data, output = self.extend_usage_data((a, b))\n",
        "                    final_copy.append((appliance, data, output))\n",
        "\n",
        "        # add single and extended appliance to x and y\n",
        "        for (a, b, c) in final_copy:\n",
        "            x.append(b)\n",
        "            y.append(c)\n",
        "\n",
        "        # number of appliances\n",
        "        num_of_combined_lists = 1\n",
        "\n",
        "        for _ in range(num_of_combined_lists):\n",
        "            copy = self.updated_calibrated_data.copy()\n",
        "            number_of_appliances = random.randint(1, len(self.appliance_gallon_dict))\n",
        "\n",
        "            selected_tuples = []\n",
        "            for _ in range(number_of_appliances):\n",
        "                random_tuple = random.choice(copy)\n",
        "                selected_tuples.append(random_tuple)\n",
        "                copy = self.remove_tuples_based_on_random_selection(random_tuple, copy)\n",
        "\n",
        "\n",
        "            # Separate the selected tuples into three lists: appliances, data, and outputs\n",
        "            appliances = [tup[0] for tup in selected_tuples]\n",
        "            datas = [tup[1] for tup in selected_tuples]\n",
        "            outputs = [tup[2] for tup in selected_tuples]\n",
        "\n",
        "            item_dict = self.appliance_gallon_dict.copy()\n",
        "\n",
        "            appliance, data, output = self.combine_multiple_lists(appliances, datas, outputs, item_dict)\n",
        "\n",
        "            x.append(data)\n",
        "            y.append(list(output.values()))\n",
        "\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def change_in_points(self, appliance_tuple):\n",
        "        \"\"\"\n",
        "        Calculate changes in water meter readings and timestamps for each appliance in the tuple.\n",
        "\n",
        "        :param appliance_tuple: tuple, containing multiple appliances and their usage data\n",
        "        :return: tuple, containing multiple appliances and their modified usage data\n",
        "        \"\"\"\n",
        "        modified_tuple = []\n",
        "\n",
        "        # Iterate over each appliance and its data\n",
        "        for appliance, data in appliance_tuple:\n",
        "            output = self.appliance_gallon_dict.copy()\n",
        "\n",
        "            # Extract timestamps and water meter readings\n",
        "            timestamps = [entry[0] for entry in data]\n",
        "            readings = [int(entry[1]) / 10.0 for entry in data]\n",
        "\n",
        "            # Calculate change in water meter reading\n",
        "            changes_readings = [readings[i + 1] - readings[i] for i in range(len(readings) - 1)]\n",
        "\n",
        "            # Calculate change in timestamps\n",
        "            changes_timestamps = [\n",
        "                (datetime.strptime(timestamps[i + 1], '%m/%d/%Y %H:%M:%S') - datetime.strptime(timestamps[i],\n",
        "                                                                                               '%m/%d/%Y %H:%M:%S')).total_seconds()\n",
        "                for i in range(len(timestamps) - 1)\n",
        "            ]\n",
        "\n",
        "            # Round down changes in timestamps to the nearest 10 seconds\n",
        "            rounded_changes_timestamps = [round(change / 10.0) * 10 for change in changes_timestamps]\n",
        "\n",
        "            # Combine timestamps and changes\n",
        "            combined_data = list(zip(rounded_changes_timestamps, changes_readings))\n",
        "\n",
        "            output[appliance[0]] = sum(pair[1] for pair in combined_data)\n",
        "\n",
        "            # Append the appliance and its modified data to the result list\n",
        "            modified_tuple.append((appliance, combined_data, list(output.values())))\n",
        "\n",
        "        return modified_tuple\n",
        "\n",
        "    def combine_multiple_lists(self, items, lists, outputs, item_dict):\n",
        "        \"\"\"\n",
        "        Combines multiple lists of (seconds, reading) tuples by sequentially inserting elements from each list into a combined list.\n",
        "\n",
        "        Parameters:\n",
        "        - lists: List[List[Tuple[int, float]]]\n",
        "            The lists to be combined, each containing tuples of (seconds, reading).\n",
        "        - items: List[Any]\n",
        "            The items associated with each list.\n",
        "        - outputs: List[List[float]]\n",
        "            The output values associated with each list.\n",
        "        - item_dict: Dict[int, float]\n",
        "            A dictionary where the key is the index of an item and the value is the cumulative reading.\n",
        "\n",
        "        Returns:\n",
        "        - Tuple:\n",
        "            - The combined item names.\n",
        "            - The combined list with elements from all input lists inserted.\n",
        "            - The updated item_dict with added readings from all input lists.\n",
        "        \"\"\"\n",
        "\n",
        "        combined_item = items[0][0]\n",
        "        combined_list = lists[0]\n",
        "        combined_output = outputs[0]\n",
        "\n",
        "        output = item_dict.copy()\n",
        "        output[combined_item] += sum(combined_output)\n",
        "\n",
        "        for i in range(1, len(lists)):\n",
        "            current_item = items[i][0]\n",
        "            current_list = lists[i]\n",
        "            current_output = outputs[i]\n",
        "\n",
        "            valid_indices = [j for j, (sec, _) in enumerate(combined_list) if sec == current_list[0][0]]\n",
        "\n",
        "            if not valid_indices:\n",
        "                print(combined_item)\n",
        "                print(current_item)\n",
        "                print(combined_list)\n",
        "                print(current_list)\n",
        "                raise ValueError(\"No valid insertion point found where the first elements match.\")\n",
        "\n",
        "            insert_index = random.choice(valid_indices)\n",
        "\n",
        "            for k, (sec, reading) in enumerate(current_list):\n",
        "                try:\n",
        "                    combined_sec, combined_reading = combined_list[insert_index + k]\n",
        "\n",
        "                    if sec < combined_sec:\n",
        "                        combined_list.insert(insert_index + k, (sec, reading))\n",
        "                        combined_sec, combined_reading = combined_list[insert_index + k + 1]\n",
        "                        combined_list[insert_index + k + 1] = (combined_sec - sec, combined_reading)\n",
        "                    elif sec > combined_sec:\n",
        "                        insert_index = insert_index + sec % 10\n",
        "                        _, combined_reading = combined_list[insert_index + k]\n",
        "                        combined_list[insert_index + k] = (sec, combined_reading + reading)\n",
        "                    else:\n",
        "                        combined_list[insert_index + k] = (sec, combined_reading + reading)\n",
        "                except IndexError:\n",
        "                    combined_list.append((sec, reading))\n",
        "\n",
        "            output[current_item] += sum(current_output)\n",
        "            combined_item += current_item\n",
        "\n",
        "            # Delete unnecessary variables within the loop\n",
        "            del current_list\n",
        "            del current_output\n",
        "            del valid_indices\n",
        "            del insert_index\n",
        "            del current_item\n",
        "            del combined_sec\n",
        "            del combined_reading\n",
        "\n",
        "        # Clean up remaining large variables before returning\n",
        "        del lists\n",
        "        del items\n",
        "        del outputs\n",
        "        del item_dict, combined_output\n",
        "\n",
        "\n",
        "        return combined_item, combined_list, output\n",
        "\n",
        "\n",
        "    def extend_usage_data(self, appliance_tuple):\n",
        "        \"\"\"\n",
        "        Extend or reduce the usage data for an appliance by adding or removing a random number of additional points.\n",
        "\n",
        "        :param appliance_tuple: tuple, (appliance_name, [(seconds, gallons)])\n",
        "        :return: tuple, (modified_usage_data, [total_gallons], output list)\n",
        "        \"\"\"\n",
        "        appliance_name, usage_data = appliance_tuple\n",
        "\n",
        "        min_modifications = -len(usage_data) + 1\n",
        "        max_modifications = len(usage_data) * 50\n",
        "\n",
        "        output = self.appliance_gallon_dict.copy()\n",
        "\n",
        "        # Determine the number of points to add or remove randomly within the specified range\n",
        "        num_modifications = random.randint(min_modifications, max_modifications)\n",
        "\n",
        "        if num_modifications > 0:\n",
        "            # Add points\n",
        "            additional_data = [random.choice(usage_data) for _ in range(num_modifications)]\n",
        "            modified_data = usage_data + additional_data\n",
        "        else:\n",
        "            # Remove points, ensuring we don't remove more points than we have\n",
        "            if len(usage_data) + num_modifications <= 0:\n",
        "                modified_data = usage_data[:1]  # Keep at least one point\n",
        "            else:\n",
        "                modified_data = usage_data[:num_modifications]\n",
        "\n",
        "        output[appliance_name[0]] = sum(pair[1] for pair in modified_data)\n",
        "        return appliance_name, modified_data, list(output.values())\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, appliance_info_dict, appliance_tuple, batch_size=32, shuffle=True):\n",
        "        self.dg = CalibrationDataGenerator(appliance_info_dict, appliance_tuple)\n",
        "        self.X, self.y = self.dg.get_data()\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.count = 0\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.X) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.count % 100 == 0:\n",
        "            print(\"HERE\")\n",
        "            #self.X, self.y = self.dg.get_data()\n",
        "        self.count += 1\n",
        "\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X_temp = [self.X[k] for k in indexes]\n",
        "        y_temp = [self.y[k] for k in indexes]\n",
        "\n",
        "        X_padded = pad_sequences(X_temp, padding='post', dtype='float32', value=0.0)\n",
        "\n",
        "        return np.array(X_padded), np.array(y_temp)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "\n",
        "# Parameters\n",
        "batch_size = 4\n",
        "\n",
        "# Data Generators\n",
        "data_generator = DataGenerator(appliance_info_dict, appliance_tuple, batch_size=batch_size)\n",
        "\"\"\"\n",
        "# Model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(None, 2)))\n",
        "model.add(tf.keras.layers.LSTM(50, return_sequences=False))\n",
        "model.add(tf.keras.layers.Dense(8))  # Number of outputs is 8\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Training\n",
        "\n",
        "# Define the filepath for saving the model\n",
        "checkpoint_filepath = 'model_checkpoint.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkp oint_filepath,\n",
        "    save_weights_only=False,  # Save the entire model\n",
        "    save_freq='epoch',  # Save every epoch\n",
        "    period=10  # Save every 10 epochs\n",
        ")\n",
        "\n",
        "# Training\n",
        "history = model.fit(data_generator, validation_data=data_generator, epochs=1000, callbacks=[checkpoint_callback])\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Masking\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Define a function to print predictions during training\n",
        "def print_predictions_and_true(epoch, logs):\n",
        "    if True:\n",
        "        print(\"\\nPredictions and True Outputs at epoch\", epoch)\n",
        "        predictions = model.predict(data_generator)\n",
        "        true_outputs = next(iter(data_generator))[1]  # Get true outputs for the batch\n",
        "        print(\"Predictions:\")\n",
        "        print(predictions)\n",
        "        print(\"True Outputs:\")\n",
        "        print(true_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Masking(mask_value=0., input_shape=(None, 2)))\n",
        "model.add(LSTM(50, return_sequences=False))\n",
        "model.add(Dense(8, activation='softmax'))  # Number of outputs\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.1), loss='mse')\n",
        "\n",
        "# Define a callback to print predictions during training\n",
        "print_callback = LambdaCallback(on_epoch_end=print_predictions_and_true)\n",
        "\n",
        "# Training\n",
        "checkpoint_filepath = 'model_checkpoint.h5'\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,  # Save the entire model\n",
        "    save_freq='epoch',  # Save every epoch\n",
        "    period=10  # Save every 10 epochs\n",
        ")\n",
        "\n",
        "# Training\n",
        "history = model.fit(data_generator, validation_data=data_generator, epochs=1000, callbacks=[checkpoint_callback])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}