{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6edOUk9mPfmL"
      },
      "outputs": [],
      "source": [
        "# Define a dictionary to hold appliance names as keys and corresponding data groups as values\n",
        "appliance_dict = {\n",
        "    \"dishwasher\": [\n",
        "        ('05/04/2024 23:19:28', '01410593'),\n",
        "        ('05/04/2024 23:19:38', '01410594'),\n",
        "        ('05/04/2024 23:19:49', '01410599'),\n",
        "        ('05/04/2024 23:19:59', '01410604'),\n",
        "        ('05/04/2024 23:20:10', '01410606'),\n",
        "        ('05/04/2024 23:20:20', '01410610'),\n",
        "        ('05/04/2024 23:20:31', '01410611'),\n",
        "        ('05/04/2024 23:20:52', '01410612'),\n",
        "        ('05/04/2024 23:21:54', '01410612'),\n",
        "        ('05/04/2024 23:22:26', '01410613'),\n",
        "        ('05/04/2024 23:23:08', '01410614'),\n",
        "        ('05/04/2024 23:23:18', '01410616'),\n",
        "        ('05/04/2024 23:23:28', '01410618'),\n",
        "        ('05/04/2024 23:23:39', '01410620')\n",
        "    ],\n",
        "\n",
        "    \"toilet_tm\": [\n",
        "        ('05/05/2024 11:52:26', '01410818'),\n",
        "        ('05/05/2024 11:52:36', '01410819'),\n",
        "        ('05/05/2024 11:52:47', '01410826'),\n",
        "        ('05/05/2024 11:52:57', '01410833'),\n",
        "    ],\n",
        "\n",
        "    \"sink_tm\": [\n",
        "        ('05/05/2024 11:56:48', '01410833'),\n",
        "        ('05/05/2024 11:56:58', '01410834'),\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "from itertools import combinations\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Function to create a combined appliance dictionary with pretend data for combined use\n",
        "def change_in_points(appliance_dict):\n",
        "    combined_data_dict = {}\n",
        "\n",
        "    # Iterate over each key-value pair in the appliance_dict\n",
        "    for appliance, data in appliance_dict.items():\n",
        "        # Extract timestamps and water meter readings\n",
        "        timestamps = [entry[0] for entry in data]\n",
        "        readings = [int(entry[1])/10.0 for entry in data]\n",
        "\n",
        "        # Calculate change in water meter reading\n",
        "        changes_readings = [0] + [readings[i+1] - readings[i] for i in range(len(readings)-1)]\n",
        "\n",
        "        # Calculate change in timestamps\n",
        "        changes_timestamps = [0] + [(datetime.strptime(timestamps[i+1], '%m/%d/%Y %H:%M:%S') - datetime.strptime(timestamps[i], '%m/%d/%Y %H:%M:%S')).total_seconds() for i in range(len(timestamps)-1)]\n",
        "\n",
        "        # Round down changes in timestamps to the nearest 10 seconds\n",
        "        rounded_changes_timestamps = [10 if change == 11 else change for change in changes_timestamps]\n",
        "\n",
        "        # Combine timestamps and changes\n",
        "        combined_data_dict[appliance] = list(zip(rounded_changes_timestamps, changes_readings))\n",
        "\n",
        "    return combined_data_dict\n",
        "\n",
        "def undo_change_in_points(combined_data):\n",
        "    # Create a dictionary to store the original data\n",
        "    original_data = {}\n",
        "\n",
        "    # Iterate over each key-value pair in the combined_data\n",
        "    for appliance, data in combined_data.items():\n",
        "        # Initialize lists to store timestamps and actual water meter readings\n",
        "        timestamps = []\n",
        "        readings = []\n",
        "\n",
        "        # Iterate over each data point\n",
        "        for i, (timestamp, change) in enumerate(data):\n",
        "            # Calculate the actual water meter reading\n",
        "            if i == 0:\n",
        "                actual_time = timestamp\n",
        "                actual_reading = change\n",
        "            else:\n",
        "                actual_time += timestamp\n",
        "                actual_reading += change\n",
        "\n",
        "            # Append the timestamp and actual reading to the lists\n",
        "\n",
        "            dt_object = datetime.utcfromtimestamp(actual_time)\n",
        "\n",
        "            a = dt_object.strftime('%m/%d/%Y %H:%M:%S')\n",
        "\n",
        "            timestamps.append(a)\n",
        "            readings.append(actual_reading)\n",
        "\n",
        "        # Store the original data in the dictionary\n",
        "        original_data[appliance] = list(zip(timestamps, readings))\n",
        "\n",
        "    return original_data\n",
        "\n",
        "def extract_features(d):\n",
        "  final = []\n",
        "  for data in d:\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data, columns=['timestamp', 'reading'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %H:%M:%S')\n",
        "    df['reading'] = df['reading'].astype(int)/10\n",
        "\n",
        "    # Calculate duration in minutes\n",
        "    duration = (df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]).total_seconds()/60\n",
        "\n",
        "    # Calculate total water consumption\n",
        "    total_water_consumption = df['reading'].iloc[-1] - df['reading'].iloc[0]\n",
        "\n",
        "    # Calculate flow rates\n",
        "    df['flow_rate'] = df['reading'].diff() / (df['timestamp'].diff().dt.total_seconds()/60)\n",
        "\n",
        "\n",
        "    # Calculate mean, max, min flow rates\n",
        "    mean_flow_rate = df['flow_rate'].mean()\n",
        "    max_flow_rate = df['flow_rate'].max()\n",
        "    min_flow_rate = df['flow_rate'].min()\n",
        "\n",
        "    # Calculate the number of flow rate changes\n",
        "    flow_rate_changes = df['flow_rate'].ne(df['flow_rate'].shift()).sum()\n",
        "\n",
        "    # Calculate the number of spikes (defined as significant jumps in flow rate)\n",
        "    spike_threshold = 10  # You can adjust the spike threshold as needed\n",
        "    number_of_spikes = (df['flow_rate'].diff().abs() > spike_threshold).sum()\n",
        "\n",
        "    # Calculate the duration of high flow (flow rate > certain threshold)\n",
        "    high_flow_threshold = 5  # You can adjust the high flow threshold as needed\n",
        "    high_flow_periods = df['flow_rate'] > high_flow_threshold\n",
        "    duration_of_high_flow = high_flow_periods.sum() * df['timestamp'].diff().dt.total_seconds().mean()\n",
        "\n",
        "    # Return extracted features\n",
        "    features = {\n",
        "        'duration': duration,\n",
        "        'total_water_consumption': total_water_consumption,\n",
        "        'mean_flow_rate': mean_flow_rate,\n",
        "        'max_flow_rate': max_flow_rate,\n",
        "        'min_flow_rate': min_flow_rate,\n",
        "        'flow_rate_changes': flow_rate_changes,\n",
        "        'number_of_spikes': number_of_spikes,\n",
        "        'duration_of_high_flow': duration_of_high_flow,\n",
        "    }\n",
        "\n",
        "    final.append([duration, total_water_consumption, mean_flow_rate, max_flow_rate, min_flow_rate, flow_rate_changes, number_of_spikes, duration_of_high_flow])\n",
        "\n",
        "  return final\n",
        "\n",
        "def one_hot(l):\n",
        "  # Initialize the result list\n",
        "  result = []\n",
        "\n",
        "  # Define the items to count\n",
        "  items = ['dishwasher', 'toilet_tm', 'sink_tm']\n",
        "\n",
        "  # Iterate over the input list and count occurrences\n",
        "  for entry in l:\n",
        "      counts = [entry.count(item) for item in items]\n",
        "      result.append(counts)\n",
        "\n",
        "  # Convert result to a numpy array for better representation\n",
        "  return np.array(result)\n",
        "\n",
        "def appliance_2(appliance_dict, keys, index=-1):\n",
        "\n",
        "  gallon_y = {}\n",
        "  for key in keys:\n",
        "    gallon_y[key] = 0\n",
        "\n",
        "  # create new appliance key\n",
        "  new_appliance = ''\n",
        "  if len(appliance_dict.keys()) != 1:\n",
        "    for key in appliance_dict.keys():\n",
        "      new_appliance += key + \" + \"\n",
        "  else:\n",
        "    new_appliance = list(appliance_dict.keys())[0] + \" +  + \" + list(appliance_dict.keys())[0] + \" + \"\n",
        "\n",
        "  new_dic = {}\n",
        "\n",
        "  # Find the longer list\n",
        "  longest_list_key = max(appliance_dict, key=lambda k: len(appliance_dict[k]))\n",
        "  longest_list = appliance_dict[longest_list_key]\n",
        "  s = 0\n",
        "  for i in longest_list:\n",
        "    s += i[1]\n",
        "  gallon_y[longest_list_key] = s\n",
        "\n",
        "  # Find the shorter list\n",
        "  shorter_list_key = min(appliance_dict, key=lambda k: len(appliance_dict[k]))\n",
        "  shorter_list = appliance_dict[shorter_list_key][1:]\n",
        "\n",
        "  new_dic[new_appliance] = longest_list[:]\n",
        "\n",
        "  c = True\n",
        "  if index == -1:\n",
        "    while c:\n",
        "      index_to_insert = random.randint(0, len(longest_list) - len(shorter_list))\n",
        "\n",
        "      # Get the difference in the first timestamp between the two lists\n",
        "\n",
        "      time_diff = longest_list[index_to_insert][0] - shorter_list[0][0]\n",
        "\n",
        "      if time_diff == 0:\n",
        "        c = False\n",
        "        for i in range(len(shorter_list)):\n",
        "          new_dic[new_appliance][index_to_insert + i] = (\n",
        "                  shorter_list[i][0],\n",
        "                  shorter_list[i][1] + longest_list[index_to_insert + i][1],\n",
        "              )\n",
        "\n",
        "    return new_appliance, new_dic[new_appliance]\n",
        "\n",
        "  else:\n",
        "    # Get the difference in the first timestamp between the two lists\n",
        "\n",
        "    time_diff = longest_list[index][0] - shorter_list[0][0]\n",
        "    #print(index)\n",
        "\n",
        "    if time_diff == 0:\n",
        "\n",
        "      for i in range(len(shorter_list)):\n",
        "          new_dic[new_appliance][index + i] = (\n",
        "                  shorter_list[i][0],\n",
        "                  shorter_list[i][1] + longest_list[index + i][1],\n",
        "              )\n",
        "\n",
        "    return new_appliance, new_dic[new_appliance]\n",
        "\n"
      ],
      "metadata": {
        "id": "4o7Os6RlPpiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = change_in_points(appliance_dict)\n",
        "\n",
        "data = {}\n",
        "data_test = {}\n",
        "\n",
        "for index1, key1 in enumerate(list(a.keys())):\n",
        "\n",
        "  # to add into\n",
        "  for index2, key2 in enumerate(list(a.keys())):\n",
        "    # print(key1, key2)\n",
        "\n",
        "    data[key1] = undo_change_in_points({key1: list(a.values())[index1]})[key1]\n",
        "\n",
        "    ################## ITERATION 1\n",
        "\n",
        "    d = {key1: list(a.values())[index1], key2: list(a.values())[index2]}\n",
        "\n",
        "    longest_list_key = max(d, key=lambda k: len(d[k]))\n",
        "    shortest_list_key = min(d, key=lambda k: len(d[k]))\n",
        "    longest_list = d[longest_list_key]\n",
        "    shorter_list = d[shortest_list_key][1:]\n",
        "\n",
        "    # print(\"iteration 1: \" + str(len(longest_list) - len(shorter_list)))\n",
        "\n",
        "\n",
        "    for i in range(len(longest_list) - len(shorter_list)):\n",
        "\n",
        "      qw, er = appliance_2(d, appliance_dict.keys(), index=i)\n",
        "\n",
        "      data[qw+str(i)] = undo_change_in_points({qw:er})[qw]\n",
        "\n",
        "    ################## ITERATION 2\n",
        "\n",
        "    d = {qw: er, key2: list(a.values())[index2]}\n",
        "\n",
        "    longest_list_key = max(d, key=lambda k: len(d[k]))\n",
        "    shortest_list_key = min(d, key=lambda k: len(d[k]))\n",
        "    longest_list = d[longest_list_key]\n",
        "    shorter_list = d[shortest_list_key][1:]\n",
        "\n",
        "    # print(\"iteration 2: \" + str(len(longest_list) - len(shorter_list)))\n",
        "\n",
        "\n",
        "    for i in range(len(longest_list) - len(shorter_list)):\n",
        "\n",
        "      qw, er = appliance_2(d, appliance_dict.keys(), index=i)\n",
        "\n",
        "      data[qw+str(i)] = undo_change_in_points({qw:er})[qw]\n",
        "\n",
        "    ################## ITERATION 3\n",
        "\n",
        "    d = {qw: er, key2: list(a.values())[index2]}\n",
        "\n",
        "    longest_list_key = max(d, key=lambda k: len(d[k]))\n",
        "    shortest_list_key = min(d, key=lambda k: len(d[k]))\n",
        "    longest_list = d[longest_list_key]\n",
        "    shorter_list = d[shortest_list_key][1:]\n",
        "\n",
        "    # print(\"iteration 3: \" + str(len(longest_list) - len(shorter_list)))\n",
        "\n",
        "    for i in range(len(longest_list) - len(shorter_list)):\n",
        "\n",
        "      qw, er = appliance_2(d, appliance_dict.keys(), index=i)\n",
        "\n",
        "      data[qw+str(i)] = undo_change_in_points({qw:er})[qw]\n",
        "\n",
        "\n",
        "    ################## ITERATION 4\n",
        "\n",
        "    d = {qw: er, key2: list(a.values())[index2]}\n",
        "\n",
        "    longest_list_key = max(d, key=lambda k: len(d[k]))\n",
        "    shortest_list_key = min(d, key=lambda k: len(d[k]))\n",
        "    longest_list = d[longest_list_key]\n",
        "    shorter_list = d[shortest_list_key][1:]\n",
        "\n",
        "    # print(\"iteration 4: \" + str(len(longest_list) - len(shorter_list)))\n",
        "\n",
        "    for i in range(len(longest_list) - len(shorter_list)):\n",
        "\n",
        "      qw, er = appliance_2(d, appliance_dict.keys(), index=i)\n",
        "\n",
        "      data[qw+str(i)] = undo_change_in_points({qw:er})[qw]\n",
        "\n",
        "    ################## ITERATION 5\n",
        "\n",
        "    d = {qw: er, key2: list(a.values())[index2]}\n",
        "\n",
        "    longest_list_key = max(d, key=lambda k: len(d[k]))\n",
        "    shortest_list_key = min(d, key=lambda k: len(d[k]))\n",
        "    longest_list = d[longest_list_key]\n",
        "    shorter_list = d[shortest_list_key][1:]\n",
        "\n",
        "    # print(\"iteration 5: \" + str(len(longest_list) - len(shorter_list)))\n",
        "\n",
        "    for i in range(len(longest_list) - len(shorter_list)):\n",
        "\n",
        "      qw, er = appliance_2(d, appliance_dict.keys(), index=i)\n",
        "\n",
        "      data[qw+str(i)] = undo_change_in_points({qw:er})[qw]\n",
        "\n",
        "\n",
        "xs = [sublist for sublist in data.values()]\n",
        "ys = [sublist for sublist in data.keys()]\n",
        "\n",
        "\n",
        "print(xs[30])\n",
        "print(ys[30])\n",
        "\n",
        "#xs_test = [sublist for sublist in data_test.values()]\n",
        "#ys_test = [sublist for sublist in data_test.keys()]\n",
        "\n",
        "xs = extract_features(xs)\n",
        "#xs_test = extract_features(xs_test)\n",
        "\n",
        "inputs = np.array(xs)\n",
        "outputs = one_hot(ys)\n",
        "\n",
        "#inputs_test = np.array(xs_test)\n",
        "#outputs_test = one_hot(ys_test)\n",
        "\n",
        "print(inputs.shape)\n",
        "print(outputs.shape)\n",
        "\n",
        "#print(inputs_test.shape)\n",
        "#print(outputs_test.shape)\n",
        "\n",
        "#print(inputs[5])\n",
        "#print(outputs[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RImrJ3XSNMV",
        "outputId": "3a1673ee-a8eb-47e5-fcd4-1d14c1e5b9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('01/01/1970 00:00:00', 0), ('01/01/1970 00:00:10', 0.10000000000582077), ('01/01/1970 00:00:20', 0.7000000000116415), ('01/01/1970 00:00:30', 1.900000000023283), ('01/01/1970 00:00:40', 2.8000000000174623), ('01/01/1970 00:00:50', 3.2000000000116415), ('01/01/1970 00:01:00', 3.3000000000174623), ('01/01/1970 00:01:21', 3.400000000023283), ('01/01/1970 00:02:23', 3.400000000023283), ('01/01/1970 00:02:55', 3.5), ('01/01/1970 00:03:37', 3.6000000000058208), ('01/01/1970 00:03:47', 3.8000000000174623), ('01/01/1970 00:03:57', 4.0), ('01/01/1970 00:04:07', 4.2000000000116415)]\n",
            "dishwasher + toilet_tm +  + toilet_tm +  + toilet_tm + 2\n",
            "(192, 8)\n",
            "(192, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xs = [sublist for sublist in data.values()]\n",
        "ys = [sublist for sublist in data.keys()]\n",
        "\n",
        "#xs_test = [sublist for sublist in data_test.values()]\n",
        "#ys_test = [sublist for sublist in data_test.keys()]\n",
        "\n",
        "xs = extract_features(xs)\n",
        "#xs_test = extract_features(xs_test)\n",
        "\n",
        "inputs = np.array(xs)\n",
        "outputs = one_hot(ys)\n",
        "\n",
        "#inputs_test = np.array(xs_test)\n",
        "#outputs_test = one_hot(ys_test)\n",
        "\n",
        "print(inputs.shape)\n",
        "print(outputs.shape)\n",
        "\n",
        "#print(inputs_test.shape)\n",
        "#print(outputs_test.shape)\n",
        "\n",
        "input_array = torch.tensor(inputs, dtype=torch.float32)\n",
        "output_array = torch.tensor(outputs, dtype=torch.float32)\n",
        "\n",
        "# Ensure input_array and output_array have the correct shapes\n",
        "assert input_array.shape[0] == output_array.shape[0], \"Number of input samples must match number of output samples\"\n",
        "assert input_array.shape[1] == 8, \"Each input sample must have 8 features\"\n",
        "assert output_array.shape[1] == 3, \"Each output sample must have 3 features\"\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_array, output_array, test_size=0.2, random_state=42)\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.output_relu = nn.ReLU()  # Ensure non-negative outputs\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.output_relu(out)  # Apply ReLU to output\n",
        "        return out\n",
        "\n",
        "input_size = 8\n",
        "hidden_size = 10\n",
        "output_size = 3\n",
        "\n",
        "model = SimpleNN(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 100000\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    outputs = model(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "print(\"Training complete\")\n",
        "\n",
        "# Testing the model\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_train)\n",
        "    test_loss = criterion(test_outputs, y_train)\n",
        "    print(f'Test Loss: {test_loss.item():.4f}')\n",
        "\n",
        "    # Optionally, you can print test predictions and actual values for comparison\n",
        "    print(\"Test Predictions:\\n\", test_outputs)\n",
        "    print(\"Actual Values:\\n\", y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HewYeev9HC-q",
        "outputId": "854739d2-499e-447d-a730-0e2ad2630893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(192, 8)\n",
            "(192, 3)\n",
            "Epoch [100/100000], Loss: 2.5968\n",
            "Epoch [200/100000], Loss: 2.5505\n",
            "Epoch [300/100000], Loss: 2.5260\n",
            "Epoch [400/100000], Loss: 2.5188\n",
            "Epoch [500/100000], Loss: 2.5120\n",
            "Epoch [600/100000], Loss: 2.5052\n",
            "Epoch [700/100000], Loss: 2.4979\n",
            "Epoch [800/100000], Loss: 2.4920\n",
            "Epoch [900/100000], Loss: 2.4833\n",
            "Epoch [1000/100000], Loss: 2.4861\n",
            "Epoch [1100/100000], Loss: 2.4720\n",
            "Epoch [1200/100000], Loss: 2.4678\n",
            "Epoch [1300/100000], Loss: 2.4646\n",
            "Epoch [1400/100000], Loss: 2.4615\n",
            "Epoch [1500/100000], Loss: 2.4589\n",
            "Epoch [1600/100000], Loss: 2.4564\n",
            "Epoch [1700/100000], Loss: 2.4541\n",
            "Epoch [1800/100000], Loss: 2.4520\n",
            "Epoch [1900/100000], Loss: 2.4499\n",
            "Epoch [2000/100000], Loss: 2.4480\n",
            "Epoch [2100/100000], Loss: 2.4471\n",
            "Epoch [2200/100000], Loss: 2.4444\n",
            "Epoch [2300/100000], Loss: 2.4426\n",
            "Epoch [2400/100000], Loss: 2.4428\n",
            "Epoch [2500/100000], Loss: 2.4377\n",
            "Epoch [2600/100000], Loss: 2.2161\n",
            "Epoch [2700/100000], Loss: 1.3144\n",
            "Epoch [2800/100000], Loss: 1.1192\n",
            "Epoch [2900/100000], Loss: 1.0626\n",
            "Epoch [3000/100000], Loss: 1.0453\n",
            "Epoch [3100/100000], Loss: 1.0265\n",
            "Epoch [3200/100000], Loss: 1.0168\n",
            "Epoch [3300/100000], Loss: 1.0154\n",
            "Epoch [3400/100000], Loss: 1.0062\n",
            "Epoch [3500/100000], Loss: 1.0024\n",
            "Epoch [3600/100000], Loss: 1.0000\n",
            "Epoch [3700/100000], Loss: 0.9984\n",
            "Epoch [3800/100000], Loss: 0.9951\n",
            "Epoch [3900/100000], Loss: 0.9938\n",
            "Epoch [4000/100000], Loss: 0.9918\n",
            "Epoch [4100/100000], Loss: 0.9910\n",
            "Epoch [4200/100000], Loss: 0.9928\n",
            "Epoch [4300/100000], Loss: 0.9873\n",
            "Epoch [4400/100000], Loss: 0.9883\n",
            "Epoch [4500/100000], Loss: 0.9825\n",
            "Epoch [4600/100000], Loss: 0.9799\n",
            "Epoch [4700/100000], Loss: 0.9779\n",
            "Epoch [4800/100000], Loss: 0.9757\n",
            "Epoch [4900/100000], Loss: 0.9808\n",
            "Epoch [5000/100000], Loss: 0.9801\n",
            "Epoch [5100/100000], Loss: 0.9703\n",
            "Epoch [5200/100000], Loss: 0.9677\n",
            "Epoch [5300/100000], Loss: 0.9678\n",
            "Epoch [5400/100000], Loss: 0.9665\n",
            "Epoch [5500/100000], Loss: 0.9622\n",
            "Epoch [5600/100000], Loss: 0.9677\n",
            "Epoch [5700/100000], Loss: 0.9580\n",
            "Epoch [5800/100000], Loss: 0.9568\n",
            "Epoch [5900/100000], Loss: 0.9551\n",
            "Epoch [6000/100000], Loss: 0.9534\n",
            "Epoch [6100/100000], Loss: 0.9530\n",
            "Epoch [6200/100000], Loss: 0.9513\n",
            "Epoch [6300/100000], Loss: 0.9506\n",
            "Epoch [6400/100000], Loss: 0.9489\n",
            "Epoch [6500/100000], Loss: 0.9485\n",
            "Epoch [6600/100000], Loss: 0.9472\n",
            "Epoch [6700/100000], Loss: 0.9466\n",
            "Epoch [6800/100000], Loss: 0.9480\n",
            "Epoch [6900/100000], Loss: 0.9468\n",
            "Epoch [7000/100000], Loss: 0.9552\n",
            "Epoch [7100/100000], Loss: 0.9471\n",
            "Epoch [7200/100000], Loss: 0.9457\n",
            "Epoch [7300/100000], Loss: 0.9459\n",
            "Epoch [7400/100000], Loss: 0.9455\n",
            "Epoch [7500/100000], Loss: 0.9456\n",
            "Epoch [7600/100000], Loss: 0.9462\n",
            "Epoch [7700/100000], Loss: 0.9471\n",
            "Epoch [7800/100000], Loss: 0.9457\n",
            "Epoch [7900/100000], Loss: 0.9431\n",
            "Epoch [8000/100000], Loss: 0.9425\n",
            "Epoch [8100/100000], Loss: 0.9439\n",
            "Epoch [8200/100000], Loss: 0.9423\n",
            "Epoch [8300/100000], Loss: 0.9422\n",
            "Epoch [8400/100000], Loss: 0.9448\n",
            "Epoch [8500/100000], Loss: 0.9447\n",
            "Epoch [8600/100000], Loss: 0.9440\n",
            "Epoch [8700/100000], Loss: 0.9438\n",
            "Epoch [8800/100000], Loss: 0.9441\n",
            "Epoch [8900/100000], Loss: 0.9433\n",
            "Epoch [9000/100000], Loss: 0.9426\n",
            "Epoch [9100/100000], Loss: 0.9418\n",
            "Epoch [9200/100000], Loss: 0.9417\n",
            "Epoch [9300/100000], Loss: 0.9422\n",
            "Epoch [9400/100000], Loss: 0.9456\n",
            "Epoch [9500/100000], Loss: 0.9429\n",
            "Epoch [9600/100000], Loss: 0.9465\n",
            "Epoch [9700/100000], Loss: 0.9416\n",
            "Epoch [9800/100000], Loss: 0.9653\n",
            "Epoch [9900/100000], Loss: 0.9422\n",
            "Epoch [10000/100000], Loss: 0.9415\n",
            "Epoch [10100/100000], Loss: 0.9414\n",
            "Epoch [10200/100000], Loss: 0.9417\n",
            "Epoch [10300/100000], Loss: 0.9414\n",
            "Epoch [10400/100000], Loss: 0.9414\n",
            "Epoch [10500/100000], Loss: 0.9415\n",
            "Epoch [10600/100000], Loss: 0.9414\n",
            "Epoch [10700/100000], Loss: 0.9421\n",
            "Epoch [10800/100000], Loss: 0.9415\n",
            "Epoch [10900/100000], Loss: 0.9413\n",
            "Epoch [11000/100000], Loss: 0.9413\n",
            "Epoch [11100/100000], Loss: 0.9413\n",
            "Epoch [11200/100000], Loss: 0.9413\n",
            "Epoch [11300/100000], Loss: 0.9413\n",
            "Epoch [11400/100000], Loss: 0.9423\n",
            "Epoch [11500/100000], Loss: 0.9525\n",
            "Epoch [11600/100000], Loss: 0.9419\n",
            "Epoch [11700/100000], Loss: 0.9412\n",
            "Epoch [11800/100000], Loss: 0.9536\n",
            "Epoch [11900/100000], Loss: 0.9412\n",
            "Epoch [12000/100000], Loss: 0.9412\n",
            "Epoch [12100/100000], Loss: 0.9412\n",
            "Epoch [12200/100000], Loss: 0.9411\n",
            "Epoch [12300/100000], Loss: 0.9512\n",
            "Epoch [12400/100000], Loss: 0.9411\n",
            "Epoch [12500/100000], Loss: 0.9411\n",
            "Epoch [12600/100000], Loss: 0.9411\n",
            "Epoch [12700/100000], Loss: 0.9412\n",
            "Epoch [12800/100000], Loss: 0.9411\n",
            "Epoch [12900/100000], Loss: 0.9411\n",
            "Epoch [13000/100000], Loss: 0.9411\n",
            "Epoch [13100/100000], Loss: 0.9420\n",
            "Epoch [13200/100000], Loss: 0.9410\n",
            "Epoch [13300/100000], Loss: 0.9410\n",
            "Epoch [13400/100000], Loss: 0.9410\n",
            "Epoch [13500/100000], Loss: 0.9411\n",
            "Epoch [13600/100000], Loss: 0.9412\n",
            "Epoch [13700/100000], Loss: 0.9441\n",
            "Epoch [13800/100000], Loss: 0.9410\n",
            "Epoch [13900/100000], Loss: 0.9416\n",
            "Epoch [14000/100000], Loss: 0.9410\n",
            "Epoch [14100/100000], Loss: 0.9410\n",
            "Epoch [14200/100000], Loss: 0.9410\n",
            "Epoch [14300/100000], Loss: 0.9499\n",
            "Epoch [14400/100000], Loss: 0.9409\n",
            "Epoch [14500/100000], Loss: 0.9410\n",
            "Epoch [14600/100000], Loss: 0.9409\n",
            "Epoch [14700/100000], Loss: 0.9479\n",
            "Epoch [14800/100000], Loss: 0.9409\n",
            "Epoch [14900/100000], Loss: 0.9409\n",
            "Epoch [15000/100000], Loss: 0.9434\n",
            "Epoch [15100/100000], Loss: 0.9410\n",
            "Epoch [15200/100000], Loss: 0.9409\n",
            "Epoch [15300/100000], Loss: 0.9409\n",
            "Epoch [15400/100000], Loss: 0.9409\n",
            "Epoch [15500/100000], Loss: 0.9409\n",
            "Epoch [15600/100000], Loss: 0.9409\n",
            "Epoch [15700/100000], Loss: 0.9409\n",
            "Epoch [15800/100000], Loss: 0.9408\n",
            "Epoch [15900/100000], Loss: 0.9565\n",
            "Epoch [16000/100000], Loss: 0.9410\n",
            "Epoch [16100/100000], Loss: 0.9409\n",
            "Epoch [16200/100000], Loss: 0.9409\n",
            "Epoch [16300/100000], Loss: 0.9408\n",
            "Epoch [16400/100000], Loss: 0.9408\n",
            "Epoch [16500/100000], Loss: 0.9408\n",
            "Epoch [16600/100000], Loss: 0.9408\n",
            "Epoch [16700/100000], Loss: 0.9408\n",
            "Epoch [16800/100000], Loss: 0.9408\n",
            "Epoch [16900/100000], Loss: 0.9408\n",
            "Epoch [17000/100000], Loss: 0.9408\n",
            "Epoch [17100/100000], Loss: 0.9409\n",
            "Epoch [17200/100000], Loss: 0.9408\n",
            "Epoch [17300/100000], Loss: 0.9408\n",
            "Epoch [17400/100000], Loss: 0.9408\n",
            "Epoch [17500/100000], Loss: 0.9408\n",
            "Epoch [17600/100000], Loss: 0.9407\n",
            "Epoch [17700/100000], Loss: 0.9408\n",
            "Epoch [17800/100000], Loss: 0.9415\n",
            "Epoch [17900/100000], Loss: 0.9602\n",
            "Epoch [18000/100000], Loss: 0.9420\n",
            "Epoch [18100/100000], Loss: 0.9423\n",
            "Epoch [18200/100000], Loss: 0.9411\n",
            "Epoch [18300/100000], Loss: 0.9412\n",
            "Epoch [18400/100000], Loss: 0.9420\n",
            "Epoch [18500/100000], Loss: 0.9409\n",
            "Epoch [18600/100000], Loss: 0.9412\n",
            "Epoch [18700/100000], Loss: 0.9414\n",
            "Epoch [18800/100000], Loss: 0.9461\n",
            "Epoch [18900/100000], Loss: 0.9407\n",
            "Epoch [19000/100000], Loss: 0.9460\n",
            "Epoch [19100/100000], Loss: 0.9407\n",
            "Epoch [19200/100000], Loss: 0.9467\n",
            "Epoch [19300/100000], Loss: 0.9407\n",
            "Epoch [19400/100000], Loss: 0.9407\n",
            "Epoch [19500/100000], Loss: 0.9407\n",
            "Epoch [19600/100000], Loss: 0.9414\n",
            "Epoch [19700/100000], Loss: 0.9410\n",
            "Epoch [19800/100000], Loss: 0.9406\n",
            "Epoch [19900/100000], Loss: 0.9418\n",
            "Epoch [20000/100000], Loss: 0.9417\n",
            "Epoch [20100/100000], Loss: 0.9406\n",
            "Epoch [20200/100000], Loss: 0.9411\n",
            "Epoch [20300/100000], Loss: 0.9406\n",
            "Epoch [20400/100000], Loss: 0.9411\n",
            "Epoch [20500/100000], Loss: 0.9406\n",
            "Epoch [20600/100000], Loss: 0.9406\n",
            "Epoch [20700/100000], Loss: 0.9407\n",
            "Epoch [20800/100000], Loss: 0.9406\n",
            "Epoch [20900/100000], Loss: 0.9406\n",
            "Epoch [21000/100000], Loss: 0.9407\n",
            "Epoch [21100/100000], Loss: 0.9406\n",
            "Epoch [21200/100000], Loss: 0.9408\n",
            "Epoch [21300/100000], Loss: 0.9407\n",
            "Epoch [21400/100000], Loss: 0.9406\n",
            "Epoch [21500/100000], Loss: 0.9405\n",
            "Epoch [21600/100000], Loss: 0.9405\n",
            "Epoch [21700/100000], Loss: 0.9408\n",
            "Epoch [21800/100000], Loss: 0.9405\n",
            "Epoch [21900/100000], Loss: 0.9406\n",
            "Epoch [22000/100000], Loss: 0.9405\n",
            "Epoch [22100/100000], Loss: 0.9406\n",
            "Epoch [22200/100000], Loss: 0.9405\n",
            "Epoch [22300/100000], Loss: 0.9405\n",
            "Epoch [22400/100000], Loss: 0.9407\n",
            "Epoch [22500/100000], Loss: 0.9405\n",
            "Epoch [22600/100000], Loss: 0.9405\n",
            "Epoch [22700/100000], Loss: 0.9413\n",
            "Epoch [22800/100000], Loss: 0.9405\n",
            "Epoch [22900/100000], Loss: 0.9405\n",
            "Epoch [23000/100000], Loss: 0.9405\n",
            "Epoch [23100/100000], Loss: 0.9404\n",
            "Epoch [23200/100000], Loss: 0.9405\n",
            "Epoch [23300/100000], Loss: 0.9405\n",
            "Epoch [23400/100000], Loss: 0.9404\n",
            "Epoch [23500/100000], Loss: 0.9481\n",
            "Epoch [23600/100000], Loss: 0.9404\n",
            "Epoch [23700/100000], Loss: 0.9404\n",
            "Epoch [23800/100000], Loss: 0.9404\n",
            "Epoch [23900/100000], Loss: 0.9404\n",
            "Epoch [24000/100000], Loss: 0.9462\n",
            "Epoch [24100/100000], Loss: 0.9404\n",
            "Epoch [24200/100000], Loss: 0.9404\n",
            "Epoch [24300/100000], Loss: 0.9404\n",
            "Epoch [24400/100000], Loss: 0.9405\n",
            "Epoch [24500/100000], Loss: 0.9405\n",
            "Epoch [24600/100000], Loss: 0.9404\n",
            "Epoch [24700/100000], Loss: 0.9404\n",
            "Epoch [24800/100000], Loss: 0.9410\n",
            "Epoch [24900/100000], Loss: 0.9404\n",
            "Epoch [25000/100000], Loss: 0.9405\n",
            "Epoch [25100/100000], Loss: 0.9404\n",
            "Epoch [25200/100000], Loss: 0.9404\n",
            "Epoch [25300/100000], Loss: 0.9403\n",
            "Epoch [25400/100000], Loss: 0.9426\n",
            "Epoch [25500/100000], Loss: 0.9403\n",
            "Epoch [25600/100000], Loss: 0.9437\n",
            "Epoch [25700/100000], Loss: 0.9403\n",
            "Epoch [25800/100000], Loss: 0.9415\n",
            "Epoch [25900/100000], Loss: 0.9403\n",
            "Epoch [26000/100000], Loss: 0.9571\n",
            "Epoch [26100/100000], Loss: 0.9403\n",
            "Epoch [26200/100000], Loss: 0.9403\n",
            "Epoch [26300/100000], Loss: 0.9410\n",
            "Epoch [26400/100000], Loss: 0.9403\n",
            "Epoch [26500/100000], Loss: 0.9403\n",
            "Epoch [26600/100000], Loss: 0.9403\n",
            "Epoch [26700/100000], Loss: 0.9403\n",
            "Epoch [26800/100000], Loss: 0.9412\n",
            "Epoch [26900/100000], Loss: 0.9403\n",
            "Epoch [27000/100000], Loss: 0.9411\n",
            "Epoch [27100/100000], Loss: 0.9403\n",
            "Epoch [27200/100000], Loss: 0.9403\n",
            "Epoch [27300/100000], Loss: 0.9494\n",
            "Epoch [27400/100000], Loss: 0.9403\n",
            "Epoch [27500/100000], Loss: 0.9411\n",
            "Epoch [27600/100000], Loss: 0.9403\n",
            "Epoch [27700/100000], Loss: 0.9402\n",
            "Epoch [27800/100000], Loss: 0.9404\n",
            "Epoch [27900/100000], Loss: 0.9405\n",
            "Epoch [28000/100000], Loss: 0.9403\n",
            "Epoch [28100/100000], Loss: 0.9402\n",
            "Epoch [28200/100000], Loss: 0.9410\n",
            "Epoch [28300/100000], Loss: 0.9402\n",
            "Epoch [28400/100000], Loss: 0.9402\n",
            "Epoch [28500/100000], Loss: 0.9402\n",
            "Epoch [28600/100000], Loss: 0.9402\n",
            "Epoch [28700/100000], Loss: 0.9402\n",
            "Epoch [28800/100000], Loss: 0.9403\n",
            "Epoch [28900/100000], Loss: 0.9402\n",
            "Epoch [29000/100000], Loss: 0.9402\n",
            "Epoch [29100/100000], Loss: 0.9420\n",
            "Epoch [29200/100000], Loss: 0.9402\n",
            "Epoch [29300/100000], Loss: 0.9415\n",
            "Epoch [29400/100000], Loss: 0.9404\n",
            "Epoch [29500/100000], Loss: 0.9402\n",
            "Epoch [29600/100000], Loss: 0.9402\n",
            "Epoch [29700/100000], Loss: 0.9402\n",
            "Epoch [29800/100000], Loss: 0.9402\n",
            "Epoch [29900/100000], Loss: 0.9822\n",
            "Epoch [30000/100000], Loss: 0.9402\n",
            "Epoch [30100/100000], Loss: 0.9401\n",
            "Epoch [30200/100000], Loss: 0.9405\n",
            "Epoch [30300/100000], Loss: 0.9403\n",
            "Epoch [30400/100000], Loss: 0.9401\n",
            "Epoch [30500/100000], Loss: 0.9401\n",
            "Epoch [30600/100000], Loss: 0.9402\n",
            "Epoch [30700/100000], Loss: 0.9401\n",
            "Epoch [30800/100000], Loss: 0.9401\n",
            "Epoch [30900/100000], Loss: 0.9401\n",
            "Epoch [31000/100000], Loss: 0.9401\n",
            "Epoch [31100/100000], Loss: 0.9402\n",
            "Epoch [31200/100000], Loss: 0.9401\n",
            "Epoch [31300/100000], Loss: 0.9401\n",
            "Epoch [31400/100000], Loss: 0.9401\n",
            "Epoch [31500/100000], Loss: 0.9401\n",
            "Epoch [31600/100000], Loss: 0.9637\n",
            "Epoch [31700/100000], Loss: 0.9401\n",
            "Epoch [31800/100000], Loss: 0.9401\n",
            "Epoch [31900/100000], Loss: 0.9401\n",
            "Epoch [32000/100000], Loss: 0.9402\n",
            "Epoch [32100/100000], Loss: 0.9401\n",
            "Epoch [32200/100000], Loss: 0.9402\n",
            "Epoch [32300/100000], Loss: 0.9401\n",
            "Epoch [32400/100000], Loss: 0.9401\n",
            "Epoch [32500/100000], Loss: 0.9401\n",
            "Epoch [32600/100000], Loss: 0.9401\n",
            "Epoch [32700/100000], Loss: 0.9401\n",
            "Epoch [32800/100000], Loss: 0.9401\n",
            "Epoch [32900/100000], Loss: 0.9401\n",
            "Epoch [33000/100000], Loss: 0.9400\n",
            "Epoch [33100/100000], Loss: 0.9400\n",
            "Epoch [33200/100000], Loss: 0.9400\n",
            "Epoch [33300/100000], Loss: 0.9531\n",
            "Epoch [33400/100000], Loss: 0.9400\n",
            "Epoch [33500/100000], Loss: 0.9400\n",
            "Epoch [33600/100000], Loss: 0.9400\n",
            "Epoch [33700/100000], Loss: 0.9401\n",
            "Epoch [33800/100000], Loss: 0.9405\n",
            "Epoch [33900/100000], Loss: 0.9400\n",
            "Epoch [34000/100000], Loss: 0.9400\n",
            "Epoch [34100/100000], Loss: 0.9479\n",
            "Epoch [34200/100000], Loss: 0.9400\n",
            "Epoch [34300/100000], Loss: 0.9414\n",
            "Epoch [34400/100000], Loss: 0.9400\n",
            "Epoch [34500/100000], Loss: 0.9400\n",
            "Epoch [34600/100000], Loss: 0.9400\n",
            "Epoch [34700/100000], Loss: 0.9400\n",
            "Epoch [34800/100000], Loss: 0.9400\n",
            "Epoch [34900/100000], Loss: 0.9400\n",
            "Epoch [35000/100000], Loss: 0.9400\n",
            "Epoch [35100/100000], Loss: 0.9400\n",
            "Epoch [35200/100000], Loss: 0.9400\n",
            "Epoch [35300/100000], Loss: 0.9402\n",
            "Epoch [35400/100000], Loss: 0.9401\n",
            "Epoch [35500/100000], Loss: 0.9400\n",
            "Epoch [35600/100000], Loss: 0.9479\n",
            "Epoch [35700/100000], Loss: 0.9400\n",
            "Epoch [35800/100000], Loss: 0.9629\n",
            "Epoch [35900/100000], Loss: 0.9400\n",
            "Epoch [36000/100000], Loss: 0.9400\n",
            "Epoch [36100/100000], Loss: 0.9399\n",
            "Epoch [36200/100000], Loss: 0.9400\n",
            "Epoch [36300/100000], Loss: 0.9400\n",
            "Epoch [36400/100000], Loss: 0.9400\n",
            "Epoch [36500/100000], Loss: 0.9399\n",
            "Epoch [36600/100000], Loss: 0.9399\n",
            "Epoch [36700/100000], Loss: 0.9403\n",
            "Epoch [36800/100000], Loss: 0.9399\n",
            "Epoch [36900/100000], Loss: 0.9402\n",
            "Epoch [37000/100000], Loss: 0.9399\n",
            "Epoch [37100/100000], Loss: 0.9399\n",
            "Epoch [37200/100000], Loss: 0.9399\n",
            "Epoch [37300/100000], Loss: 0.9399\n",
            "Epoch [37400/100000], Loss: 0.9446\n",
            "Epoch [37500/100000], Loss: 0.9399\n",
            "Epoch [37600/100000], Loss: 0.9403\n",
            "Epoch [37700/100000], Loss: 0.9399\n",
            "Epoch [37800/100000], Loss: 0.9399\n",
            "Epoch [37900/100000], Loss: 0.9399\n",
            "Epoch [38000/100000], Loss: 0.9551\n",
            "Epoch [38100/100000], Loss: 0.9399\n",
            "Epoch [38200/100000], Loss: 0.9399\n",
            "Epoch [38300/100000], Loss: 0.9399\n",
            "Epoch [38400/100000], Loss: 0.9399\n",
            "Epoch [38500/100000], Loss: 0.9399\n",
            "Epoch [38600/100000], Loss: 0.9399\n",
            "Epoch [38700/100000], Loss: 0.9399\n",
            "Epoch [38800/100000], Loss: 0.9399\n",
            "Epoch [38900/100000], Loss: 0.9402\n",
            "Epoch [39000/100000], Loss: 0.9399\n",
            "Epoch [39100/100000], Loss: 0.9406\n",
            "Epoch [39200/100000], Loss: 0.9399\n",
            "Epoch [39300/100000], Loss: 0.9399\n",
            "Epoch [39400/100000], Loss: 0.9436\n",
            "Epoch [39500/100000], Loss: 0.9399\n",
            "Epoch [39600/100000], Loss: 0.9400\n",
            "Epoch [39700/100000], Loss: 0.9399\n",
            "Epoch [39800/100000], Loss: 0.9399\n",
            "Epoch [39900/100000], Loss: 0.9403\n",
            "Epoch [40000/100000], Loss: 0.9399\n",
            "Epoch [40100/100000], Loss: 0.9864\n",
            "Epoch [40200/100000], Loss: 0.9399\n",
            "Epoch [40300/100000], Loss: 0.9399\n",
            "Epoch [40400/100000], Loss: 0.9399\n",
            "Epoch [40500/100000], Loss: 0.9399\n",
            "Epoch [40600/100000], Loss: 0.9399\n",
            "Epoch [40700/100000], Loss: 0.9400\n",
            "Epoch [40800/100000], Loss: 0.9399\n",
            "Epoch [40900/100000], Loss: 0.9399\n",
            "Epoch [41000/100000], Loss: 0.9736\n",
            "Epoch [41100/100000], Loss: 0.9399\n",
            "Epoch [41200/100000], Loss: 0.9401\n",
            "Epoch [41300/100000], Loss: 0.9399\n",
            "Epoch [41400/100000], Loss: 0.9399\n",
            "Epoch [41500/100000], Loss: 0.9398\n",
            "Epoch [41600/100000], Loss: 0.9399\n",
            "Epoch [41700/100000], Loss: 0.9398\n",
            "Epoch [41800/100000], Loss: 0.9404\n",
            "Epoch [41900/100000], Loss: 0.9398\n",
            "Epoch [42000/100000], Loss: 0.9398\n",
            "Epoch [42100/100000], Loss: 0.9399\n",
            "Epoch [42200/100000], Loss: 0.9398\n",
            "Epoch [42300/100000], Loss: 0.9398\n",
            "Epoch [42400/100000], Loss: 0.9399\n",
            "Epoch [42500/100000], Loss: 0.9398\n",
            "Epoch [42600/100000], Loss: 0.9398\n",
            "Epoch [42700/100000], Loss: 0.9499\n",
            "Epoch [42800/100000], Loss: 0.9398\n",
            "Epoch [42900/100000], Loss: 0.9398\n",
            "Epoch [43000/100000], Loss: 0.9411\n",
            "Epoch [43100/100000], Loss: 0.9398\n",
            "Epoch [43200/100000], Loss: 0.9398\n",
            "Epoch [43300/100000], Loss: 0.9398\n",
            "Epoch [43400/100000], Loss: 0.9399\n",
            "Epoch [43500/100000], Loss: 0.9398\n",
            "Epoch [43600/100000], Loss: 0.9461\n",
            "Epoch [43700/100000], Loss: 0.9398\n",
            "Epoch [43800/100000], Loss: 0.9398\n",
            "Epoch [43900/100000], Loss: 0.9398\n",
            "Epoch [44000/100000], Loss: 0.9398\n",
            "Epoch [44100/100000], Loss: 0.9398\n",
            "Epoch [44200/100000], Loss: 0.9411\n",
            "Epoch [44300/100000], Loss: 0.9398\n",
            "Epoch [44400/100000], Loss: 0.9398\n",
            "Epoch [44500/100000], Loss: 0.9398\n",
            "Epoch [44600/100000], Loss: 0.9513\n",
            "Epoch [44700/100000], Loss: 0.9398\n",
            "Epoch [44800/100000], Loss: 0.9868\n",
            "Epoch [44900/100000], Loss: 0.9398\n",
            "Epoch [45000/100000], Loss: 0.9398\n",
            "Epoch [45100/100000], Loss: 0.9398\n",
            "Epoch [45200/100000], Loss: 0.9398\n",
            "Epoch [45300/100000], Loss: 0.9398\n",
            "Epoch [45400/100000], Loss: 0.9404\n",
            "Epoch [45500/100000], Loss: 0.9398\n",
            "Epoch [45600/100000], Loss: 0.9398\n",
            "Epoch [45700/100000], Loss: 0.9398\n",
            "Epoch [45800/100000], Loss: 0.9591\n",
            "Epoch [45900/100000], Loss: 0.9398\n",
            "Epoch [46000/100000], Loss: 0.9398\n",
            "Epoch [46100/100000], Loss: 0.9565\n",
            "Epoch [46200/100000], Loss: 0.9398\n",
            "Epoch [46300/100000], Loss: 0.9451\n",
            "Epoch [46400/100000], Loss: 0.9398\n",
            "Epoch [46500/100000], Loss: 0.9398\n",
            "Epoch [46600/100000], Loss: 0.9398\n",
            "Epoch [46700/100000], Loss: 0.9398\n",
            "Epoch [46800/100000], Loss: 0.9399\n",
            "Epoch [46900/100000], Loss: 0.9398\n",
            "Epoch [47000/100000], Loss: 0.9398\n",
            "Epoch [47100/100000], Loss: 0.9649\n",
            "Epoch [47200/100000], Loss: 0.9398\n",
            "Epoch [47300/100000], Loss: 0.9398\n",
            "Epoch [47400/100000], Loss: 0.9399\n",
            "Epoch [47500/100000], Loss: 0.9398\n",
            "Epoch [47600/100000], Loss: 0.9398\n",
            "Epoch [47700/100000], Loss: 0.9398\n",
            "Epoch [47800/100000], Loss: 0.9398\n",
            "Epoch [47900/100000], Loss: 0.9398\n",
            "Epoch [48000/100000], Loss: 0.9446\n",
            "Epoch [48100/100000], Loss: 0.9398\n",
            "Epoch [48200/100000], Loss: 0.9398\n",
            "Epoch [48300/100000], Loss: 0.9398\n",
            "Epoch [48400/100000], Loss: 0.9398\n",
            "Epoch [48500/100000], Loss: 0.9398\n",
            "Epoch [48600/100000], Loss: 0.9398\n",
            "Epoch [48700/100000], Loss: 0.9398\n",
            "Epoch [48800/100000], Loss: 0.9400\n",
            "Epoch [48900/100000], Loss: 0.9398\n",
            "Epoch [49000/100000], Loss: 0.9398\n",
            "Epoch [49100/100000], Loss: 0.9398\n",
            "Epoch [49200/100000], Loss: 0.9398\n",
            "Epoch [49300/100000], Loss: 0.9398\n",
            "Epoch [49400/100000], Loss: 0.9398\n",
            "Epoch [49500/100000], Loss: 0.9398\n",
            "Epoch [49600/100000], Loss: 0.9398\n",
            "Epoch [49700/100000], Loss: 0.9410\n",
            "Epoch [49800/100000], Loss: 0.9398\n",
            "Epoch [49900/100000], Loss: 0.9398\n",
            "Epoch [50000/100000], Loss: 0.9398\n",
            "Epoch [50100/100000], Loss: 0.9398\n",
            "Epoch [50200/100000], Loss: 0.9398\n",
            "Epoch [50300/100000], Loss: 0.9398\n",
            "Epoch [50400/100000], Loss: 0.9398\n",
            "Epoch [50500/100000], Loss: 0.9398\n",
            "Epoch [50600/100000], Loss: 0.9398\n",
            "Epoch [50700/100000], Loss: 0.9398\n",
            "Epoch [50800/100000], Loss: 0.9399\n",
            "Epoch [50900/100000], Loss: 0.9398\n",
            "Epoch [51000/100000], Loss: 0.9398\n",
            "Epoch [51100/100000], Loss: 0.9398\n",
            "Epoch [51200/100000], Loss: 0.9398\n",
            "Epoch [51300/100000], Loss: 0.9398\n",
            "Epoch [51400/100000], Loss: 0.9630\n",
            "Epoch [51500/100000], Loss: 0.9398\n",
            "Epoch [51600/100000], Loss: 0.9398\n",
            "Epoch [51700/100000], Loss: 0.9418\n",
            "Epoch [51800/100000], Loss: 0.9398\n",
            "Epoch [51900/100000], Loss: 0.9517\n",
            "Epoch [52000/100000], Loss: 0.9398\n",
            "Epoch [52100/100000], Loss: 0.9398\n",
            "Epoch [52200/100000], Loss: 0.9398\n",
            "Epoch [52300/100000], Loss: 0.9398\n",
            "Epoch [52400/100000], Loss: 0.9751\n",
            "Epoch [52500/100000], Loss: 0.9398\n",
            "Epoch [52600/100000], Loss: 0.9398\n",
            "Epoch [52700/100000], Loss: 0.9398\n",
            "Epoch [52800/100000], Loss: 0.9398\n",
            "Epoch [52900/100000], Loss: 0.9398\n",
            "Epoch [53000/100000], Loss: 0.9398\n",
            "Epoch [53100/100000], Loss: 0.9398\n",
            "Epoch [53200/100000], Loss: 0.9398\n",
            "Epoch [53300/100000], Loss: 0.9405\n",
            "Epoch [53400/100000], Loss: 0.9398\n",
            "Epoch [53500/100000], Loss: 0.9403\n",
            "Epoch [53600/100000], Loss: 0.9398\n",
            "Epoch [53700/100000], Loss: 0.9403\n",
            "Epoch [53800/100000], Loss: 0.9398\n",
            "Epoch [53900/100000], Loss: 0.9398\n",
            "Epoch [54000/100000], Loss: 0.9589\n",
            "Epoch [54100/100000], Loss: 0.9398\n",
            "Epoch [54200/100000], Loss: 0.9398\n",
            "Epoch [54300/100000], Loss: 0.9398\n",
            "Epoch [54400/100000], Loss: 0.9398\n",
            "Epoch [54500/100000], Loss: 0.9398\n",
            "Epoch [54600/100000], Loss: 0.9398\n",
            "Epoch [54700/100000], Loss: 0.9398\n",
            "Epoch [54800/100000], Loss: 0.9398\n",
            "Epoch [54900/100000], Loss: 0.9398\n",
            "Epoch [55000/100000], Loss: 0.9398\n",
            "Epoch [55100/100000], Loss: 0.9398\n",
            "Epoch [55200/100000], Loss: 0.9398\n",
            "Epoch [55300/100000], Loss: 0.9398\n",
            "Epoch [55400/100000], Loss: 0.9398\n",
            "Epoch [55500/100000], Loss: 0.9398\n",
            "Epoch [55600/100000], Loss: 0.9400\n",
            "Epoch [55700/100000], Loss: 0.9398\n",
            "Epoch [55800/100000], Loss: 0.9429\n",
            "Epoch [55900/100000], Loss: 0.9398\n",
            "Epoch [56000/100000], Loss: 0.9398\n",
            "Epoch [56100/100000], Loss: 0.9398\n",
            "Epoch [56200/100000], Loss: 0.9398\n",
            "Epoch [56300/100000], Loss: 0.9398\n",
            "Epoch [56400/100000], Loss: 0.9398\n",
            "Epoch [56500/100000], Loss: 0.9401\n",
            "Epoch [56600/100000], Loss: 0.9398\n",
            "Epoch [56700/100000], Loss: 0.9398\n",
            "Epoch [56800/100000], Loss: 0.9398\n",
            "Epoch [56900/100000], Loss: 0.9398\n",
            "Epoch [57000/100000], Loss: 0.9410\n",
            "Epoch [57100/100000], Loss: 0.9398\n",
            "Epoch [57200/100000], Loss: 0.9398\n",
            "Epoch [57300/100000], Loss: 0.9475\n",
            "Epoch [57400/100000], Loss: 0.9398\n",
            "Epoch [57500/100000], Loss: 0.9398\n",
            "Epoch [57600/100000], Loss: 0.9423\n",
            "Epoch [57700/100000], Loss: 0.9398\n",
            "Epoch [57800/100000], Loss: 0.9398\n",
            "Epoch [57900/100000], Loss: 0.9398\n",
            "Epoch [58000/100000], Loss: 0.9398\n",
            "Epoch [58100/100000], Loss: 0.9398\n",
            "Epoch [58200/100000], Loss: 0.9398\n",
            "Epoch [58300/100000], Loss: 0.9400\n",
            "Epoch [58400/100000], Loss: 0.9398\n",
            "Epoch [58500/100000], Loss: 0.9401\n",
            "Epoch [58600/100000], Loss: 0.9398\n",
            "Epoch [58700/100000], Loss: 0.9398\n",
            "Epoch [58800/100000], Loss: 0.9400\n",
            "Epoch [58900/100000], Loss: 0.9398\n",
            "Epoch [59000/100000], Loss: 0.9398\n",
            "Epoch [59100/100000], Loss: 0.9398\n",
            "Epoch [59200/100000], Loss: 0.9398\n",
            "Epoch [59300/100000], Loss: 0.9398\n",
            "Epoch [59400/100000], Loss: 0.9398\n",
            "Epoch [59500/100000], Loss: 0.9398\n",
            "Epoch [59600/100000], Loss: 0.9398\n",
            "Epoch [59700/100000], Loss: 0.9399\n",
            "Epoch [59800/100000], Loss: 0.9398\n",
            "Epoch [59900/100000], Loss: 0.9547\n",
            "Epoch [60000/100000], Loss: 0.9398\n",
            "Epoch [60100/100000], Loss: 0.9398\n",
            "Epoch [60200/100000], Loss: 0.9398\n",
            "Epoch [60300/100000], Loss: 0.9398\n",
            "Epoch [60400/100000], Loss: 0.9398\n",
            "Epoch [60500/100000], Loss: 0.9398\n",
            "Epoch [60600/100000], Loss: 0.9398\n",
            "Epoch [60700/100000], Loss: 0.9399\n",
            "Epoch [60800/100000], Loss: 0.9398\n",
            "Epoch [60900/100000], Loss: 0.9436\n",
            "Epoch [61000/100000], Loss: 0.9398\n",
            "Epoch [61100/100000], Loss: 0.9398\n",
            "Epoch [61200/100000], Loss: 0.9398\n",
            "Epoch [61300/100000], Loss: 0.9398\n",
            "Epoch [61400/100000], Loss: 0.9624\n",
            "Epoch [61500/100000], Loss: 0.9398\n",
            "Epoch [61600/100000], Loss: 0.9398\n",
            "Epoch [61700/100000], Loss: 0.9400\n",
            "Epoch [61800/100000], Loss: 0.9398\n",
            "Epoch [61900/100000], Loss: 0.9490\n",
            "Epoch [62000/100000], Loss: 0.9398\n",
            "Epoch [62100/100000], Loss: 0.9398\n",
            "Epoch [62200/100000], Loss: 0.9398\n",
            "Epoch [62300/100000], Loss: 0.9398\n",
            "Epoch [62400/100000], Loss: 0.9398\n",
            "Epoch [62500/100000], Loss: 0.9398\n",
            "Epoch [62600/100000], Loss: 0.9398\n",
            "Epoch [62700/100000], Loss: 0.9398\n",
            "Epoch [62800/100000], Loss: 0.9398\n",
            "Epoch [62900/100000], Loss: 0.9398\n",
            "Epoch [63000/100000], Loss: 0.9398\n",
            "Epoch [63100/100000], Loss: 0.9400\n",
            "Epoch [63200/100000], Loss: 0.9398\n",
            "Epoch [63300/100000], Loss: 0.9398\n",
            "Epoch [63400/100000], Loss: 0.9398\n",
            "Epoch [63500/100000], Loss: 0.9398\n",
            "Epoch [63600/100000], Loss: 0.9398\n",
            "Epoch [63700/100000], Loss: 0.9398\n",
            "Epoch [63800/100000], Loss: 0.9400\n",
            "Epoch [63900/100000], Loss: 0.9398\n",
            "Epoch [64000/100000], Loss: 0.9511\n",
            "Epoch [64100/100000], Loss: 0.9398\n",
            "Epoch [64200/100000], Loss: 0.9398\n",
            "Epoch [64300/100000], Loss: 0.9399\n",
            "Epoch [64400/100000], Loss: 0.9398\n",
            "Epoch [64500/100000], Loss: 0.9398\n",
            "Epoch [64600/100000], Loss: 0.9398\n",
            "Epoch [64700/100000], Loss: 0.9398\n",
            "Epoch [64800/100000], Loss: 0.9398\n",
            "Epoch [64900/100000], Loss: 0.9398\n",
            "Epoch [65000/100000], Loss: 0.9398\n",
            "Epoch [65100/100000], Loss: 0.9398\n",
            "Epoch [65200/100000], Loss: 0.9398\n",
            "Epoch [65300/100000], Loss: 0.9398\n",
            "Epoch [65400/100000], Loss: 0.9399\n",
            "Epoch [65500/100000], Loss: 0.9398\n",
            "Epoch [65600/100000], Loss: 0.9401\n",
            "Epoch [65700/100000], Loss: 0.9398\n",
            "Epoch [65800/100000], Loss: 0.9398\n",
            "Epoch [65900/100000], Loss: 0.9410\n",
            "Epoch [66000/100000], Loss: 0.9398\n",
            "Epoch [66100/100000], Loss: 0.9398\n",
            "Epoch [66200/100000], Loss: 0.9398\n",
            "Epoch [66300/100000], Loss: 0.9398\n",
            "Epoch [66400/100000], Loss: 0.9398\n",
            "Epoch [66500/100000], Loss: 0.9398\n",
            "Epoch [66600/100000], Loss: 0.9398\n",
            "Epoch [66700/100000], Loss: 0.9398\n",
            "Epoch [66800/100000], Loss: 0.9398\n",
            "Epoch [66900/100000], Loss: 0.9398\n",
            "Epoch [67000/100000], Loss: 0.9398\n",
            "Epoch [67100/100000], Loss: 1.0280\n",
            "Epoch [67200/100000], Loss: 0.9398\n",
            "Epoch [67300/100000], Loss: 0.9398\n",
            "Epoch [67400/100000], Loss: 0.9398\n",
            "Epoch [67500/100000], Loss: 0.9398\n",
            "Epoch [67600/100000], Loss: 0.9398\n",
            "Epoch [67700/100000], Loss: 0.9398\n",
            "Epoch [67800/100000], Loss: 0.9398\n",
            "Epoch [67900/100000], Loss: 0.9398\n",
            "Epoch [68000/100000], Loss: 0.9398\n",
            "Epoch [68100/100000], Loss: 0.9398\n",
            "Epoch [68200/100000], Loss: 0.9398\n",
            "Epoch [68300/100000], Loss: 0.9399\n",
            "Epoch [68400/100000], Loss: 0.9413\n",
            "Epoch [68500/100000], Loss: 0.9398\n",
            "Epoch [68600/100000], Loss: 0.9398\n",
            "Epoch [68700/100000], Loss: 0.9398\n",
            "Epoch [68800/100000], Loss: 0.9398\n",
            "Epoch [68900/100000], Loss: 0.9398\n",
            "Epoch [69000/100000], Loss: 0.9398\n",
            "Epoch [69100/100000], Loss: 0.9398\n",
            "Epoch [69200/100000], Loss: 0.9398\n",
            "Epoch [69300/100000], Loss: 0.9398\n",
            "Epoch [69400/100000], Loss: 0.9402\n",
            "Epoch [69500/100000], Loss: 0.9398\n",
            "Epoch [69600/100000], Loss: 0.9398\n",
            "Epoch [69700/100000], Loss: 0.9398\n",
            "Epoch [69800/100000], Loss: 0.9398\n",
            "Epoch [69900/100000], Loss: 0.9398\n",
            "Epoch [70000/100000], Loss: 0.9398\n",
            "Epoch [70100/100000], Loss: 0.9831\n",
            "Epoch [70200/100000], Loss: 0.9398\n",
            "Epoch [70300/100000], Loss: 0.9398\n",
            "Epoch [70400/100000], Loss: 0.9398\n",
            "Epoch [70500/100000], Loss: 0.9398\n",
            "Epoch [70600/100000], Loss: 0.9397\n",
            "Epoch [70700/100000], Loss: 0.9398\n",
            "Epoch [70800/100000], Loss: 0.9398\n",
            "Epoch [70900/100000], Loss: 0.9398\n",
            "Epoch [71000/100000], Loss: 0.9398\n",
            "Epoch [71100/100000], Loss: 0.9399\n",
            "Epoch [71200/100000], Loss: 0.9398\n",
            "Epoch [71300/100000], Loss: 0.9398\n",
            "Epoch [71400/100000], Loss: 0.9522\n",
            "Epoch [71500/100000], Loss: 0.9398\n",
            "Epoch [71600/100000], Loss: 0.9638\n",
            "Epoch [71700/100000], Loss: 0.9398\n",
            "Epoch [71800/100000], Loss: 0.9398\n",
            "Epoch [71900/100000], Loss: 0.9398\n",
            "Epoch [72000/100000], Loss: 0.9398\n",
            "Epoch [72100/100000], Loss: 0.9397\n",
            "Epoch [72200/100000], Loss: 0.9445\n",
            "Epoch [72300/100000], Loss: 0.9398\n",
            "Epoch [72400/100000], Loss: 0.9400\n",
            "Epoch [72500/100000], Loss: 0.9398\n",
            "Epoch [72600/100000], Loss: 0.9397\n",
            "Epoch [72700/100000], Loss: 0.9398\n",
            "Epoch [72800/100000], Loss: 0.9397\n",
            "Epoch [72900/100000], Loss: 0.9425\n",
            "Epoch [73000/100000], Loss: 0.9398\n",
            "Epoch [73100/100000], Loss: 0.9398\n",
            "Epoch [73200/100000], Loss: 0.9398\n",
            "Epoch [73300/100000], Loss: 0.9397\n",
            "Epoch [73400/100000], Loss: 0.9397\n",
            "Epoch [73500/100000], Loss: 0.9397\n",
            "Epoch [73600/100000], Loss: 0.9397\n",
            "Epoch [73700/100000], Loss: 0.9398\n",
            "Epoch [73800/100000], Loss: 0.9397\n",
            "Epoch [73900/100000], Loss: 0.9397\n",
            "Epoch [74000/100000], Loss: 0.9408\n",
            "Epoch [74100/100000], Loss: 0.9398\n",
            "Epoch [74200/100000], Loss: 0.9398\n",
            "Epoch [74300/100000], Loss: 0.9398\n",
            "Epoch [74400/100000], Loss: 0.9398\n",
            "Epoch [74500/100000], Loss: 0.9397\n",
            "Epoch [74600/100000], Loss: 0.9397\n",
            "Epoch [74700/100000], Loss: 0.9400\n",
            "Epoch [74800/100000], Loss: 0.9403\n",
            "Epoch [74900/100000], Loss: 0.9397\n",
            "Epoch [75000/100000], Loss: 0.9397\n",
            "Epoch [75100/100000], Loss: 0.9398\n",
            "Epoch [75200/100000], Loss: 0.9397\n",
            "Epoch [75300/100000], Loss: 0.9397\n",
            "Epoch [75400/100000], Loss: 0.9403\n",
            "Epoch [75500/100000], Loss: 0.9397\n",
            "Epoch [75600/100000], Loss: 0.9582\n",
            "Epoch [75700/100000], Loss: 0.9398\n",
            "Epoch [75800/100000], Loss: 0.9397\n",
            "Epoch [75900/100000], Loss: 0.9397\n",
            "Epoch [76000/100000], Loss: 0.9397\n",
            "Epoch [76100/100000], Loss: 0.9397\n",
            "Epoch [76200/100000], Loss: 0.9423\n",
            "Epoch [76300/100000], Loss: 0.9397\n",
            "Epoch [76400/100000], Loss: 0.9415\n",
            "Epoch [76500/100000], Loss: 0.9397\n",
            "Epoch [76600/100000], Loss: 0.9397\n",
            "Epoch [76700/100000], Loss: 0.9454\n",
            "Epoch [76800/100000], Loss: 0.9397\n",
            "Epoch [76900/100000], Loss: 0.9397\n",
            "Epoch [77000/100000], Loss: 0.9397\n",
            "Epoch [77100/100000], Loss: 0.9397\n",
            "Epoch [77200/100000], Loss: 0.9397\n",
            "Epoch [77300/100000], Loss: 0.9398\n",
            "Epoch [77400/100000], Loss: 0.9397\n",
            "Epoch [77500/100000], Loss: 0.9398\n",
            "Epoch [77600/100000], Loss: 0.9397\n",
            "Epoch [77700/100000], Loss: 0.9397\n",
            "Epoch [77800/100000], Loss: 0.9399\n",
            "Epoch [77900/100000], Loss: 0.9397\n",
            "Epoch [78000/100000], Loss: 0.9397\n",
            "Epoch [78100/100000], Loss: 0.9397\n",
            "Epoch [78200/100000], Loss: 0.9397\n",
            "Epoch [78300/100000], Loss: 0.9683\n",
            "Epoch [78400/100000], Loss: 0.9397\n",
            "Epoch [78500/100000], Loss: 0.9397\n",
            "Epoch [78600/100000], Loss: 0.9398\n",
            "Epoch [78700/100000], Loss: 0.9397\n",
            "Epoch [78800/100000], Loss: 0.9397\n",
            "Epoch [78900/100000], Loss: 0.9398\n",
            "Epoch [79000/100000], Loss: 0.9397\n",
            "Epoch [79100/100000], Loss: 0.9397\n",
            "Epoch [79200/100000], Loss: 0.9397\n",
            "Epoch [79300/100000], Loss: 0.9397\n",
            "Epoch [79400/100000], Loss: 0.9397\n",
            "Epoch [79500/100000], Loss: 0.9579\n",
            "Epoch [79600/100000], Loss: 0.9398\n",
            "Epoch [79700/100000], Loss: 0.9397\n",
            "Epoch [79800/100000], Loss: 0.9397\n",
            "Epoch [79900/100000], Loss: 0.9397\n",
            "Epoch [80000/100000], Loss: 0.9397\n",
            "Epoch [80100/100000], Loss: 0.9397\n",
            "Epoch [80200/100000], Loss: 0.9420\n",
            "Epoch [80300/100000], Loss: 0.9397\n",
            "Epoch [80400/100000], Loss: 0.9403\n",
            "Epoch [80500/100000], Loss: 0.9398\n",
            "Epoch [80600/100000], Loss: 0.9397\n",
            "Epoch [80700/100000], Loss: 0.9397\n",
            "Epoch [80800/100000], Loss: 0.9397\n",
            "Epoch [80900/100000], Loss: 0.9397\n",
            "Epoch [81000/100000], Loss: 0.9397\n",
            "Epoch [81100/100000], Loss: 0.9460\n",
            "Epoch [81200/100000], Loss: 0.9398\n",
            "Epoch [81300/100000], Loss: 0.9397\n",
            "Epoch [81400/100000], Loss: 0.9397\n",
            "Epoch [81500/100000], Loss: 0.9397\n",
            "Epoch [81600/100000], Loss: 0.9397\n",
            "Epoch [81700/100000], Loss: 0.9397\n",
            "Epoch [81800/100000], Loss: 0.9410\n",
            "Epoch [81900/100000], Loss: 0.9397\n",
            "Epoch [82000/100000], Loss: 0.9397\n",
            "Epoch [82100/100000], Loss: 0.9398\n",
            "Epoch [82200/100000], Loss: 0.9397\n",
            "Epoch [82300/100000], Loss: 0.9397\n",
            "Epoch [82400/100000], Loss: 0.9399\n",
            "Epoch [82500/100000], Loss: 0.9397\n",
            "Epoch [82600/100000], Loss: 0.9397\n",
            "Epoch [82700/100000], Loss: 0.9397\n",
            "Epoch [82800/100000], Loss: 0.9397\n",
            "Epoch [82900/100000], Loss: 0.9398\n",
            "Epoch [83000/100000], Loss: 0.9397\n",
            "Epoch [83100/100000], Loss: 0.9399\n",
            "Epoch [83200/100000], Loss: 0.9397\n",
            "Epoch [83300/100000], Loss: 0.9397\n",
            "Epoch [83400/100000], Loss: 0.9397\n",
            "Epoch [83500/100000], Loss: 0.9413\n",
            "Epoch [83600/100000], Loss: 0.9397\n",
            "Epoch [83700/100000], Loss: 0.9397\n",
            "Epoch [83800/100000], Loss: 0.9399\n",
            "Epoch [83900/100000], Loss: 0.9397\n",
            "Epoch [84000/100000], Loss: 0.9397\n",
            "Epoch [84100/100000], Loss: 0.9397\n",
            "Epoch [84200/100000], Loss: 0.9397\n",
            "Epoch [84300/100000], Loss: 0.9402\n",
            "Epoch [84400/100000], Loss: 0.9397\n",
            "Epoch [84500/100000], Loss: 0.9398\n",
            "Epoch [84600/100000], Loss: 0.9397\n",
            "Epoch [84700/100000], Loss: 0.9397\n",
            "Epoch [84800/100000], Loss: 0.9397\n",
            "Epoch [84900/100000], Loss: 0.9398\n",
            "Epoch [85000/100000], Loss: 0.9397\n",
            "Epoch [85100/100000], Loss: 0.9397\n",
            "Epoch [85200/100000], Loss: 0.9397\n",
            "Epoch [85300/100000], Loss: 0.9397\n",
            "Epoch [85400/100000], Loss: 0.9398\n",
            "Epoch [85500/100000], Loss: 0.9397\n",
            "Epoch [85600/100000], Loss: 0.9398\n",
            "Epoch [85700/100000], Loss: 0.9397\n",
            "Epoch [85800/100000], Loss: 0.9402\n",
            "Epoch [85900/100000], Loss: 0.9397\n",
            "Epoch [86000/100000], Loss: 0.9397\n",
            "Epoch [86100/100000], Loss: 0.9483\n",
            "Epoch [86200/100000], Loss: 0.9397\n",
            "Epoch [86300/100000], Loss: 0.9397\n",
            "Epoch [86400/100000], Loss: 1.0118\n",
            "Epoch [86500/100000], Loss: 0.9398\n",
            "Epoch [86600/100000], Loss: 0.9397\n",
            "Epoch [86700/100000], Loss: 0.9397\n",
            "Epoch [86800/100000], Loss: 0.9397\n",
            "Epoch [86900/100000], Loss: 0.9397\n",
            "Epoch [87000/100000], Loss: 0.9397\n",
            "Epoch [87100/100000], Loss: 0.9397\n",
            "Epoch [87200/100000], Loss: 0.9397\n",
            "Epoch [87300/100000], Loss: 0.9398\n",
            "Epoch [87400/100000], Loss: 0.9397\n",
            "Epoch [87500/100000], Loss: 0.9397\n",
            "Epoch [87600/100000], Loss: 0.9404\n",
            "Epoch [87700/100000], Loss: 0.9397\n",
            "Epoch [87800/100000], Loss: 0.9397\n",
            "Epoch [87900/100000], Loss: 0.9508\n",
            "Epoch [88000/100000], Loss: 0.9397\n",
            "Epoch [88100/100000], Loss: 0.9397\n",
            "Epoch [88200/100000], Loss: 0.9397\n",
            "Epoch [88300/100000], Loss: 0.9398\n",
            "Epoch [88400/100000], Loss: 0.9397\n",
            "Epoch [88500/100000], Loss: 0.9397\n",
            "Epoch [88600/100000], Loss: 0.9397\n",
            "Epoch [88700/100000], Loss: 0.9397\n",
            "Epoch [88800/100000], Loss: 0.9401\n",
            "Epoch [88900/100000], Loss: 0.9397\n",
            "Epoch [89000/100000], Loss: 0.9401\n",
            "Epoch [89100/100000], Loss: 0.9397\n",
            "Epoch [89200/100000], Loss: 0.9397\n",
            "Epoch [89300/100000], Loss: 0.9407\n",
            "Epoch [89400/100000], Loss: 0.9397\n",
            "Epoch [89500/100000], Loss: 1.0787\n",
            "Epoch [89600/100000], Loss: 0.9397\n",
            "Epoch [89700/100000], Loss: 0.9397\n",
            "Epoch [89800/100000], Loss: 0.9397\n",
            "Epoch [89900/100000], Loss: 0.9397\n",
            "Epoch [90000/100000], Loss: 0.9397\n",
            "Epoch [90100/100000], Loss: 0.9401\n",
            "Epoch [90200/100000], Loss: 0.9397\n",
            "Epoch [90300/100000], Loss: 0.9397\n",
            "Epoch [90400/100000], Loss: 0.9398\n",
            "Epoch [90500/100000], Loss: 0.9397\n",
            "Epoch [90600/100000], Loss: 0.9397\n",
            "Epoch [90700/100000], Loss: 0.9399\n",
            "Epoch [90800/100000], Loss: 0.9397\n",
            "Epoch [90900/100000], Loss: 0.9397\n",
            "Epoch [91000/100000], Loss: 0.9433\n",
            "Epoch [91100/100000], Loss: 0.9397\n",
            "Epoch [91200/100000], Loss: 0.9526\n",
            "Epoch [91300/100000], Loss: 0.9397\n",
            "Epoch [91400/100000], Loss: 0.9397\n",
            "Epoch [91500/100000], Loss: 0.9397\n",
            "Epoch [91600/100000], Loss: 0.9397\n",
            "Epoch [91700/100000], Loss: 0.9397\n",
            "Epoch [91800/100000], Loss: 0.9397\n",
            "Epoch [91900/100000], Loss: 0.9397\n",
            "Epoch [92000/100000], Loss: 0.9397\n",
            "Epoch [92100/100000], Loss: 0.9397\n",
            "Epoch [92200/100000], Loss: 0.9397\n",
            "Epoch [92300/100000], Loss: 0.9723\n",
            "Epoch [92400/100000], Loss: 0.9398\n",
            "Epoch [92500/100000], Loss: 0.9397\n",
            "Epoch [92600/100000], Loss: 0.9397\n",
            "Epoch [92700/100000], Loss: 0.9400\n",
            "Epoch [92800/100000], Loss: 0.9397\n",
            "Epoch [92900/100000], Loss: 0.9397\n",
            "Epoch [93000/100000], Loss: 0.9398\n",
            "Epoch [93100/100000], Loss: 0.9397\n",
            "Epoch [93200/100000], Loss: 0.9397\n",
            "Epoch [93300/100000], Loss: 0.9397\n",
            "Epoch [93400/100000], Loss: 0.9397\n",
            "Epoch [93500/100000], Loss: 0.9398\n",
            "Epoch [93600/100000], Loss: 0.9398\n",
            "Epoch [93700/100000], Loss: 0.9397\n",
            "Epoch [93800/100000], Loss: 0.9400\n",
            "Epoch [93900/100000], Loss: 0.9397\n",
            "Epoch [94000/100000], Loss: 0.9397\n",
            "Epoch [94100/100000], Loss: 0.9397\n",
            "Epoch [94200/100000], Loss: 0.9398\n",
            "Epoch [94300/100000], Loss: 0.9399\n",
            "Epoch [94400/100000], Loss: 0.9397\n",
            "Epoch [94500/100000], Loss: 0.9397\n",
            "Epoch [94600/100000], Loss: 0.9397\n",
            "Epoch [94700/100000], Loss: 0.9397\n",
            "Epoch [94800/100000], Loss: 0.9397\n",
            "Epoch [94900/100000], Loss: 0.9398\n",
            "Epoch [95000/100000], Loss: 0.9397\n",
            "Epoch [95100/100000], Loss: 0.9408\n",
            "Epoch [95200/100000], Loss: 0.9397\n",
            "Epoch [95300/100000], Loss: 0.9397\n",
            "Epoch [95400/100000], Loss: 0.9397\n",
            "Epoch [95500/100000], Loss: 0.9397\n",
            "Epoch [95600/100000], Loss: 0.9397\n",
            "Epoch [95700/100000], Loss: 0.9398\n",
            "Epoch [95800/100000], Loss: 0.9397\n",
            "Epoch [95900/100000], Loss: 0.9421\n",
            "Epoch [96000/100000], Loss: 0.9398\n",
            "Epoch [96100/100000], Loss: 0.9397\n",
            "Epoch [96200/100000], Loss: 0.9397\n",
            "Epoch [96300/100000], Loss: 0.9397\n",
            "Epoch [96400/100000], Loss: 0.9397\n",
            "Epoch [96500/100000], Loss: 0.9397\n",
            "Epoch [96600/100000], Loss: 0.9397\n",
            "Epoch [96700/100000], Loss: 0.9397\n",
            "Epoch [96800/100000], Loss: 0.9833\n",
            "Epoch [96900/100000], Loss: 0.9397\n",
            "Epoch [97000/100000], Loss: 0.9397\n",
            "Epoch [97100/100000], Loss: 0.9397\n",
            "Epoch [97200/100000], Loss: 0.9397\n",
            "Epoch [97300/100000], Loss: 0.9397\n",
            "Epoch [97400/100000], Loss: 0.9545\n",
            "Epoch [97500/100000], Loss: 0.9397\n",
            "Epoch [97600/100000], Loss: 0.9434\n",
            "Epoch [97700/100000], Loss: 0.9397\n",
            "Epoch [97800/100000], Loss: 0.9397\n",
            "Epoch [97900/100000], Loss: 0.9397\n",
            "Epoch [98000/100000], Loss: 0.9397\n",
            "Epoch [98100/100000], Loss: 0.9397\n",
            "Epoch [98200/100000], Loss: 0.9397\n",
            "Epoch [98300/100000], Loss: 0.9398\n",
            "Epoch [98400/100000], Loss: 0.9397\n",
            "Epoch [98500/100000], Loss: 0.9397\n",
            "Epoch [98600/100000], Loss: 0.9397\n",
            "Epoch [98700/100000], Loss: 0.9398\n",
            "Epoch [98800/100000], Loss: 0.9397\n",
            "Epoch [98900/100000], Loss: 0.9397\n",
            "Epoch [99000/100000], Loss: 0.9397\n",
            "Epoch [99100/100000], Loss: 0.9397\n",
            "Epoch [99200/100000], Loss: 0.9397\n",
            "Epoch [99300/100000], Loss: 0.9397\n",
            "Epoch [99400/100000], Loss: 0.9398\n",
            "Epoch [99500/100000], Loss: 0.9586\n",
            "Epoch [99600/100000], Loss: 0.9397\n",
            "Epoch [99700/100000], Loss: 0.9397\n",
            "Epoch [99800/100000], Loss: 0.9412\n",
            "Epoch [99900/100000], Loss: 0.9397\n",
            "Epoch [100000/100000], Loss: 0.9397\n",
            "Training complete\n",
            "Test Loss: 0.9397\n",
            "Test Predictions:\n",
            " tensor([[1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.0053, 3.2222, 0.0000],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [0.9955, 2.7821, 0.0000],\n",
            "        [1.0053, 3.2222, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [0.9955, 2.7821, 0.0000],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.0053, 3.2222, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.9835, 0.0000, 5.3142],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [0.9835, 0.0000, 5.3142],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [1.0150, 0.0000, 5.9044],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0053, 3.2222, 0.0000],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9955, 2.7821, 0.0000],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0150, 0.0000, 5.9044],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.0000, 1.0050, 4.9985],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [1.0018, 2.5087, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [0.9955, 2.7821, 0.0000],\n",
            "        [1.0053, 3.2222, 0.0000],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9990, 0.0000, 1.3613],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.0031, 2.4508, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 1.0050, 4.9985],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [0.0000, 2.1312, 1.0534],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [0.0000, 1.3599, 2.8748],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.9835, 0.0000, 5.3142],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [1.0172, 0.0000, 4.0830],\n",
            "        [0.0000, 0.0000, 3.5006],\n",
            "        [0.9970, 2.8883, 0.0000],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927],\n",
            "        [1.4138, 1.2587, 0.7245],\n",
            "        [0.9857, 0.0000, 3.4927]])\n",
            "Actual Values:\n",
            " tensor([[1., 0., 2.],\n",
            "        [1., 0., 4.],\n",
            "        [0., 0., 1.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 0., 2.],\n",
            "        [0., 1., 0.],\n",
            "        [1., 3., 0.],\n",
            "        [0., 1., 4.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 3., 0.],\n",
            "        [0., 1., 3.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [0., 1., 5.],\n",
            "        [0., 0., 4.],\n",
            "        [0., 3., 1.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 3.],\n",
            "        [3., 0., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 3., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 2., 0.],\n",
            "        [0., 2., 1.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [0., 1., 2.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 0., 4.],\n",
            "        [5., 0., 0.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [2., 1., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 3.],\n",
            "        [3., 1., 0.],\n",
            "        [1., 0., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [0., 6., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [0., 0., 2.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 2., 0.],\n",
            "        [0., 4., 0.],\n",
            "        [4., 1., 0.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 2.],\n",
            "        [0., 5., 1.],\n",
            "        [0., 1., 5.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 3.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 5.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [4., 0., 0.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [0., 1., 2.],\n",
            "        [4., 0., 1.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 3., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [2., 0., 1.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 5., 0.],\n",
            "        [0., 0., 3.],\n",
            "        [1., 5., 0.],\n",
            "        [1., 4., 0.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 5., 0.],\n",
            "        [0., 1., 5.],\n",
            "        [0., 4., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 3., 0.],\n",
            "        [0., 1., 4.],\n",
            "        [0., 1., 1.],\n",
            "        [2., 0., 0.],\n",
            "        [1., 5., 0.],\n",
            "        [0., 1., 1.],\n",
            "        [1., 1., 0.],\n",
            "        [0., 1., 2.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 0., 5.],\n",
            "        [1., 0., 3.],\n",
            "        [1., 0., 2.],\n",
            "        [1., 0., 5.],\n",
            "        [0., 0., 6.],\n",
            "        [1., 2., 0.],\n",
            "        [1., 0., 1.],\n",
            "        [1., 0., 4.],\n",
            "        [1., 1., 0.],\n",
            "        [1., 0., 3.],\n",
            "        [5., 0., 1.],\n",
            "        [1., 0., 4.]])\n"
          ]
        }
      ]
    }
  ]
}